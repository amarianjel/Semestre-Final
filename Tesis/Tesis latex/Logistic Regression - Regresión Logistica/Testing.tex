    \hypertarget{logistic-regression---testeo-del-algoritmo}{%
\section{Logistic Regression - Testeo del algoritmo}\label{logistic-regression---testeo-del-algoritmo}}

	En esta sección se ralizará el Testing del algoritmo Logistic Regression como en la sección \ref{nauxefve-bayes---testeo-del-algoritmo}.

    \hypertarget{predicciones-sobre-los-datos-del-testing-y-muxe9tricas-de-rendimiento}{%
\subsection{Predicciones sobre los datos del testing y métricas de rendimiento}\label{predicciones-sobre-los-datos-del-testing-y-muxe9tricas-de-rendimiento}}

	Tal como, la sección \ref{NBT:predicciones-sobre-los-datos-del-testing-y-muxe9tricas-de-rendimiento} se realizará la evaluación de métricas del Testing.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{60}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Tests \PYZhy{} Presición :}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{metrics}\PY{o}{.}\PY{n}{accuracy\PYZus{}score}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{prediccionTests}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Tests \PYZhy{} Reporte de clasificación:}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{metrics}\PY{o}{.}\PY{n}{classification\PYZus{}report}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{prediccionTests}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Tests - Presición : 0.8333333333333334
Tests - Reporte de clasificación:
               precision    recall  f1-score   support

           0       0.75      1.00      0.86         6
           1       1.00      0.67      0.80         6

    accuracy                           0.83        12
   macro avg       0.88      0.83      0.83        12
weighted avg       0.88      0.83      0.83        12

    \end{Verbatim}
    
	Por cada estado (0 y 1) la precisión de los datos del testing en el modelo tiene un valor de 75\%  y 100\% para cada estado respectivo en predicción. La exhaustividad informa la cantidad de datos capaz de identificar y, en este caso, es de un 100\% y 67\% para cada estado respectivo y, finalmente, el F1 combina los valores de precisión y exhaustividad obteniéndose un 86\% y 80\% en los estados respectivos. 
\par Lo que se busca es la precisión del modelo, por consecuencia, el algoritmo de ML Logistic Regression tiene una precisión del 83,33\% de predicción en los 12 pacientes de muestra del testing.\\

    \hypertarget{matriz-de-confusiuxf3n}{%
\subsection{Matriz de Confusión}\label{matriz-de-confusiuxf3n}}

Evaluaremos la matriz de confusión que se elaboró con los datos del testing.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{61}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{matriz} \PY{o}{=} \PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{prediccionTests}\PY{p}{)}

\PY{n}{plot\PYZus{}confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{conf\PYZus{}mat}\PY{o}{=}\PY{n}{matriz}\PY{p}{,} \PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{6}\PY{p}{,}\PY{l+m+mi}{6}\PY{p}{)}\PY{p}{,} \PY{n}{show\PYZus{}normed}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{tight\PYZus{}layout}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

\begin{center}
    	\begin{figure}[H]
	\centering
    \adjustimage{max size={0.5\linewidth}{0.9\paperheight}}{Logistic Regression - Regresión Logistica/output_97_0.png}
	\caption{Matriz de confusión de testing Logistic Regression }
	\label{fig:mctlr}
	\end{figure}
\end{center}

	En la matriz de confusión \ref{fig:mctlr}, los valores de la diagonal principal (0,0) = 6 y (1,1) = 4 corresponden con los valores estimados de forma correcta por el modelo, tanto los TN, como los TP. La otra diagonal, representa los casos en los que el modelo \textit{"se ha equivocado"}, según la matriz de confusión \ref{fig:mcenb} son (0,1) = 0 FP y (1,0) = 2 FN.
\par Las afirmaciones anteriores sugieren que las predicciones son altas, pero también existen algunos errores en la predicción.
\par Respecto al ACV, el modelo identificó a 6 pacientes que poseen un buen pronóstico (estable) y 4 pacientes que poseen un pronóstico no tan favorable, según la variable objetivo detallada en \ref{crear-columna-para-nihss_alta_estable_o_grave}. Así mismo, el modelo identifica a 2 pacientes que poseen buen pronóstico, pero en realidad poseen mal pronóstico.\\
    

    \hypertarget{logistic-regression---uso-del-algoritmo}{%
\section{Logistic Regression - Uso del algoritmo}\label{logistic-regression---uso-del-algoritmo}}

	Al igual que en la sección \ref{nauxefve-bayes---uso-del-algoritmo}, realizaremos comparaciones de predicción y probabilidad.

    \hypertarget{importancia-de-los-predictores}{%
\subsection{Importancia de los predictores}\label{importancia-de-los-predictores}}

 Al igual que la sub sección \ref{NBT:importancia-de-los-predictores}, realizaremos los procedimientos.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{62}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Predicciones probabilísticas}
\PY{c+c1}{\PYZsh{} ==============================================================================}
\PY{c+c1}{\PYZsh{} Con .predict\PYZus{}proba() se obtiene, para cada observación, la probabilidad predicha}
\PY{c+c1}{\PYZsh{} de pertenecer a cada una de las dos clases.}
\PY{n}{predicciones} \PY{o}{=} \PY{n}{lr}\PY{o}{.}\PY{n}{predict\PYZus{}proba}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}
\PY{n}{predicciones} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{predicciones}\PY{p}{,} \PY{n}{columns} \PY{o}{=} \PY{n}{lr}\PY{o}{.}\PY{n}{classes\PYZus{}}\PY{p}{)}
\PY{n}{predicciones}
\end{Verbatim}
\end{tcolorbox}

\begin{table}[H]
\centering
\setlength{\tabcolsep}{5pt}
\resizebox{0.3\textwidth}{!}{
\begin{tabular}{|c|l|l|}
\hline
\multicolumn{1}{|l|}{} & \multicolumn{1}{c|}{\textbf{0}} & \multicolumn{1}{c|}{\textbf{1}} \\ \hline \hline
\textbf{0} & 0,769731 & 0,230269 \\ \hline
\textbf{1} & 0,965470 & 0,034530 \\ \hline
\textbf{2} & 0,993616 & 0,006384 \\ \hline
\textbf{3} & 0,998082 & 0,001918 \\ \hline
\textbf{4} & 0,420635 & 0,579365 \\ \hline
\textbf{5} & 0,576335 & 0,423665 \\ \hline
\textbf{6} & 0,197545 & 0,802455 \\ \hline
\textbf{7} & 0,980097 & 0,019903 \\ \hline
\textbf{8} & 0,104532 & 0,895468 \\ \hline
\textbf{9} & 0,008064 & 0,991936 \\ \hline
\textbf{10} & 0,978317 & 0,021683 \\ \hline
\textbf{11} & 0,999660 & 0,000340 \\ \hline

\end{tabular}%
}
\caption{Predicciones probabilísticas para cada observación Logistic Regression}
\label{tab:probabilistica lr}
\end{table}

	De acuerdo a lo mostrado en la tabla \ref{tab:probabilistica lr}, se observa como ejemplo, que la tupla 0 posee un 76\% y fracción de precisión para el estado 0 y un 23\% y fracción para el estado 1, en otras palabras, el paciente posee un buen pronóstico con un 76\% de probabilidad para este algoritmo.


    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{63}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Predicciones con clasificación final}
\PY{c+c1}{\PYZsh{} ==============================================================================}
\PY{c+c1}{\PYZsh{} Con .predict() se obtiene, para cada observación, la clasificación predicha por}
\PY{c+c1}{\PYZsh{} el modelo. Esta clasificación se corresponde con la clase con mayor probabilidad.}
\PY{n}{predicciones} \PY{o}{=} \PY{n}{lr}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}
\PY{n}{predicciones} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{predicciones}\PY{p}{)}
\PY{n}{predicciones}
\end{Verbatim}
\end{tcolorbox}

\begin{table}[H]
\centering
\setlength{\tabcolsep}{10pt}
\resizebox{0.15\textwidth}{!}{
\begin{tabular}{|c|l|}
\hline
\multicolumn{1}{|l|}{} & \multicolumn{1}{c|}{\textbf{0}} \\ \hline \hline
\textbf{0} & 0 \\ \hline
\textbf{1} & 0 \\ \hline
\textbf{2} & 0 \\ \hline
\textbf{3} & 0 \\ \hline
\textbf{4} & 1 \\ \hline
\textbf{5} & 0 \\ \hline
\textbf{6} & 1 \\ \hline
\textbf{7} & 0 \\ \hline
\textbf{8} & 1 \\ \hline
\textbf{9} & 1 \\ \hline
\textbf{10} & 0 \\ \hline
\textbf{11} & 0 \\ \hline
\end{tabular}%
}
\caption{Predicciones probabilísticas con clasificación final Logistic Regression}
\label{tab:clasificacion lr}
\end{table}

	Tomaremos para interpretación la tupla número 4 de la tabla \ref{tab:clasificacion lr}. Esta tupla no pertenece al estado 0, por ende, en términos de ACV, el paciente número 4 no tiene un pronóstico favorable. 
\par Recordamos que la Matriz de Confusión \ref{fig:mctlr} poseía 4 pacientes que tenian un pronóstico menos favorable, ellos son los que se registran con el valor 1 en la columna 0 de la tabla.\\

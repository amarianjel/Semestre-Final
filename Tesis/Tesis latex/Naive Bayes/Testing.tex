    \hypertarget{nauxefve-bayes---testeo-del-algoritmo}{%
\section{Naïve Bayes - Testeo del algoritmo}\label{nauxefve-bayes---testeo-del-algoritmo}}

	El testing tiene la finalidad de llevar a cabo la prueba si el modelo funciona correctamente, identificando riesgos o errores que se produjeron en los datos. No se realizará ajustes posteriores al testing para poder
comparar los algoritmos en la sección de resultados.

    \hypertarget{predicciones-sobre-los-datos-del-testing-y-muxe9tricas-de-rendimiento}{%
\subsection{Predicciones sobre los datos del testing y métricas de rendimiento}\label{NBT:predicciones-sobre-los-datos-del-testing-y-muxe9tricas-de-rendimiento}}

	Ahora es momento de evaluar los datos ya entrenados con el testing. A continuación, se dará a concer las métricas que se evaluarón en el Estudio Empírico del capítulo 4  de la sub sección Predicciones sobre los datos de prueba y métricas de rendimiento \ref{NB:predicciones-sobre-los-datos-de-prueba-y-muxe9tricas-de-rendimiento}.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{59}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Tests \PYZhy{} Precisión :}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{metrics}\PY{o}{.}\PY{n}{accuracy\PYZus{}score}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{prediccionTests}\PY{p}{)}\PY{p}{)}
\PY{n+nb}{print}\PY{p}{(}\PY{l+s+s2}{\PYZdq{}}\PY{l+s+s2}{Tests \PYZhy{} Reporte de clasificación:}\PY{l+s+se}{\PYZbs{}n}\PY{l+s+s2}{\PYZdq{}}\PY{p}{,} \PY{n}{metrics}\PY{o}{.}\PY{n}{classification\PYZus{}report}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{prediccionTests}\PY{p}{)}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

    \begin{Verbatim}[commandchars=\\\{\}]
Tests - Precisión : 0.5833333333333334
Tests - Reporte de clasificación:
               precision    recall  f1-score   support

           0       0.55      1.00      0.71         6
           1       1.00      0.17      0.29         6

    accuracy                           0.58        12
   macro avg       0.77      0.58      0.50        12
weighted avg       0.77      0.58      0.50        12

    \end{Verbatim}

	Por cada estado (0 y 1) la precisión de los datos del testing en el modelo tiene un valor de 55\%  y 100\% para cada estado respectivo en predicción. La exhaustividad informa la cantidad de datos capaz de identificar y, en este caso, es de un 100\% y 17\% para cada estado respectivo y, finalmente, el F1 combina los valores de precisión y exhaustividad obteniéndose un 71\% y 29\% en los estados respectivos. 
\par Lo que se busca es la precisión del modelo, por consecuencia, el algoritmo de ML Naïve Bayes tiene una precisión del 58.3\% de predicción en los 12 pacientes de muestra del testing.\\

    \hypertarget{matriz-de-confusiuxf3n}{%
\subsection{Matriz de Confusión}\label{NBT:matriz-de-confusiuxf3n}}

	Evaluaremos la matriz de confusión que se elaboró con los datos del testing.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{60}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{n}{matriz} \PY{o}{=} \PY{n}{confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{y\PYZus{}test}\PY{p}{,} \PY{n}{prediccionTests}\PY{p}{)}

\PY{n}{plot\PYZus{}confusion\PYZus{}matrix}\PY{p}{(}\PY{n}{conf\PYZus{}mat}\PY{o}{=}\PY{n}{matriz}\PY{p}{,} \PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{6}\PY{p}{,}\PY{l+m+mi}{6}\PY{p}{)}\PY{p}{,} \PY{n}{show\PYZus{}normed}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
\PY{n}{plt}\PY{o}{.}\PY{n}{tight\PYZus{}layout}\PY{p}{(}\PY{p}{)}
\end{Verbatim}
\end{tcolorbox}

\begin{center}
    	\begin{figure}[H]
	\centering
    \adjustimage{max size={0.5\linewidth}{0.9\paperheight}}{Naive Bayes/output_98_0.png}
	\caption{Matriz de confusión de testing Naive Bayes}
	\label{fig:mctnb}
	\end{figure}
\end{center}
    
	En la matriz de confusión \ref{fig:mctnb}, los valores de la diagonal principal (0,0) = 6 y (1,1) = 1 corresponden con los valores estimados de forma correcta por el modelo, tanto los TN, como los TP. La otra diagonal, representa los casos en los que el modelo \textit{"se ha equivocado"}, según la matriz de confusión \ref{fig:mcenb} son (0,1) = 0 FP y (1,0) = 5 FN.
\par Las afirmaciones anteriores sugieren que la las predicciones son altas, pero también existen errores en la predicción.
\par Respecto al ACV, el modelo identifico a 6 pacientes que posee un buen pronóstico (estable) y solo 1 paciente que posee un pronóstico no tan favorable, según la variable objetivo detallada en \ref{crear-columna-para-nihss_alta_estable_o_grave}. Así mismo, el modelo identifica a 5 pacientes que poseen buen pronóstico, pero en realidad poseen mal pronóstico.\\

    \hypertarget{nauxefve-bayes---uso-del-algoritmo}{%
\section{Naïve Bayes - Uso del algoritmo}\label{nauxefve-bayes---uso-del-algoritmo}}

	El último paso de la metodología es el uso del algoritmo, nosotros lo utilizaremos para desarrollar probabilidades en los predictores. No todos los modelos poseen los mismos métodos ni atributos, por ende, se tratará de realizar comparaciones con métodos similares entre sí.\\

    \hypertarget{importancia-de-los-predictores}{%
\subsection{Importancia de los predictores}\label{NBT:importancia-de-los-predictores}}

	Por experiencia previa y contemplando los gráficos producidos en el paso 3, sabemos que algunas características no son útiles para nuestro problema de predicción. Reducir la cantidad de funciones será la mejor alternativa, lo que acotará el tiempo de ejecución, con suerte sin comprometer significativamente el rendimiento, asi podemos examinar la importancia de las funciones de nuestro modelo. La importancia de cada predictor en el modelo se calcula como la reducción total (normalizada) en el criterio de división. Si un predictor no ha sido seleccionado en ninguna división, no se ha incluido en el modelo y, por lo tanto, su importancia es 0.\\

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{61}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Predicciones probabilísticas}
\PY{c+c1}{\PYZsh{} =============================}
\PY{c+c1}{\PYZsh{} Con .predict\PYZus{}proba() se obtiene, para cada observación, la probabilidad predicha}
\PY{c+c1}{\PYZsh{} de pertenecer a cada una de las dos clases.}
\PY{n}{predicciones} \PY{o}{=} \PY{n}{nb}\PY{o}{.}\PY{n}{predict\PYZus{}proba}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}
\PY{n}{predicciones} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{predicciones}\PY{p}{,} \PY{n}{columns} \PY{o}{=} \PY{n}{nb}\PY{o}{.}\PY{n}{classes\PYZus{}}\PY{p}{)}
\PY{n}{predicciones}
\end{Verbatim}
\end{tcolorbox}

\begin{table}[H]
\centering
\setlength{\tabcolsep}{5pt}
\resizebox{0.3\textwidth}{!}{
\begin{tabular}{|c|l|l|}
\hline
\multicolumn{1}{|l|}{} & \multicolumn{1}{c|}{\textbf{0}} & \multicolumn{1}{c|}{\textbf{1}} \\ \hline \hline
\textbf{0} & 0,999617 & 0,000383 \\ \hline
\textbf{1} & 0,999992 & 8,06E-06 \\ \hline
\textbf{2} & 1 & 9,05E-08 \\ \hline
\textbf{3} & 0,999997 & 2,93E-06 \\ \hline
\textbf{4} & 1 & 4,81E-07 \\ \hline
\textbf{5} & 1 & 3,42E-07 \\ \hline
\textbf{6} & 0,999105 & 0,000895 \\ \hline
\textbf{7} & 0,999973 & 2,69E-05 \\ \hline
\textbf{8} & 0,999798 & 0,000202 \\ \hline
\textbf{9} & 9E-176 & 1 \\ \hline
\textbf{10} & 1 & 3,4E-08 \\ \hline
\textbf{11} & 1 & 0 \\ \hline
\end{tabular}%
}
\caption{Predicciones probabilísticas para cada observación Bayes}
\label{tab:probabilistica Bayes}
\end{table}
        
    Este método acepta un solo argumento que corresponde a los datos sobre los cuales se calculan las probabilidades y devuelve una matriz de listas que contienen las probabilidades de clase para los puntos de datos de entrada. 
\par En este caso, en la tabla \ref{tab:probabilistica Bayes} se observa los estados de la variable predictora (0 y 1) y el porcenteje por tupla o paciente a predecir. Por ejemplo la tupla 0 posee un 99\% y fracción de precisión para el estado 0 y un 3,83\% x $10^{-4}$ para el estado 1, en otras palabras, el paciente posee un buen pronóstico con un 99\% de probabilidad para este algoritmo.

    \begin{tcolorbox}[breakable, size=fbox, boxrule=1pt, pad at break*=1mm,colback=cellbackground, colframe=cellborder]
\prompt{In}{incolor}{62}{\boxspacing}
\begin{Verbatim}[commandchars=\\\{\}]
\PY{c+c1}{\PYZsh{} Predicciones con clasificación final}
\PY{c+c1}{\PYZsh{} ===============================}
\PY{c+c1}{\PYZsh{} Con .predict() se obtiene, para cada observación, la clasificación predicha por}
\PY{c+c1}{\PYZsh{} el modelo. Esta clasificación se corresponde con la clase con mayor probabilidad.}
\PY{n}{predicciones} \PY{o}{=} \PY{n}{nb}\PY{o}{.}\PY{n}{predict}\PY{p}{(}\PY{n}{X\PYZus{}test}\PY{p}{)}
\PY{n}{predicciones} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{n}{predicciones}\PY{p}{)}
\PY{n}{predicciones}
\end{Verbatim}
\end{tcolorbox}

\begin{table}[H]
\centering
\setlength{\tabcolsep}{10pt}
\resizebox{0.15\textwidth}{!}{
\begin{tabular}{|c|l|}
\hline
\multicolumn{1}{|l|}{} & \multicolumn{1}{c|}{\textbf{0}} \\ \hline \hline
\textbf{0} & 0 \\ \hline
\textbf{1} & 0 \\ \hline
\textbf{2} & 0 \\ \hline
\textbf{3} & 0 \\ \hline
\textbf{4} & 0 \\ \hline
\textbf{5} & 0 \\ \hline
\textbf{6} & 0 \\ \hline
\textbf{7} & 0 \\ \hline
\textbf{8} & 0 \\ \hline
\textbf{9} & 1 \\ \hline
\textbf{10} & 0 \\ \hline
\textbf{11} & 0 \\ \hline
\end{tabular}%
}
\caption{Predicciones probabilísticas con clasificación final Bayes}
\label{tab:clasificacion bayes}
\end{table}
        
    Se observa en la tabla \ref{tab:clasificacion bayes} un valor binario 0 o 1, donde se muestra el valor que toma la variable desarrollada en el modelo. El valor 1 demuestra que la tupla no pertence al estado 0 de la variable predictora, y por el contrario, el estado 0 demuestra que predice el estado en esa tupla. Sin embargo, estos resultaos de clasificación final, son los que el modelo clasifica, si hubiera un error, esté se analiza en la Matriz de Confusión \ref{fig:mctnb}.
\par Recordemos que Matriz de Confusión \ref{fig:mctnb} poseía solo 1 paciente que pertencía a que tenia un pronóstico menos favorable (estado 1), en este caso, en la tupla o paciente número 9 de la tabla \ref{clatab:clasificacion bayes}, la clasificación predicha por el modelo apunta que es 1, es decir, no alcanza a ser parte de ese estado; por el contrario, las demás tuplas las reconoce que pertencen a ese estado (tienen buen pronóstico en terminos de ACV).\\
    
    
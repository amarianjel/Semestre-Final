@article{Dong2018,
   abstract = {Machine-learning technology powers many aspects of modern society. Compared to the conventional machine learning techniques that were limited in processing natural data in the raw form, deep learning allows computational models to learn representations of data with multiple levels of abstraction. In this study, an improved deep learning model is proposed to explore the complex interactions among roadways, traffic, environmental elements, and traffic crashes. The proposed model includes two modules, an unsupervised feature learning module to identify functional network between the explanatory variables and the feature representations and a supervised fine tuning module to perform traffic crash prediction. To address the unobserved heterogeneity issues in the traffic crash prediction, a multivariate negative binomial (MVNB) model is embedding into the supervised fine tuning module as a regression layer. The proposed model was applied to the dataset that was collected from Knox County in Tennessee to validate the performances. The results indicate that the feature learning module identifies relational information between the explanatory variables and the feature representations, which reduces the dimensionality of the input and preserves the original information. The proposed model that includes the MVNB regression layer in the supervised fine tuning module can better account for differential distribution patterns in traffic crashes across injury severities and provides superior traffic crash predictions. The findings suggest that the proposed model is a superior alternative for traffic crash predictions and the average accuracy of the prediction that was measured by RMSD can be improved by 84.58\% and 158.27\% compared to the deep learning model without the regression layer and the SVM model, respectively.},
   author = {Chunjiao Dong and Chunfu Shao and Juan Li and Zhihua Xiong},
   doi = {10.1155/2018/3869106},
   issn = {20423195},
   journal = {Journal of Advanced Transportation},
   publisher = {Hindawi Limited},
   title = {An Improved Deep Learning Model for Traffic Crash Prediction},
   volume = {2018},
   year = {2018},
}
@book{Carola,
   author = {Carola Figueroa Flores},
   city = {Bellaterra},
   isbn = {9788494853197},
   month = {2},
   title = {Visual Saliency for Object Recognition, and Object Recognition for Visual Saliency},
   year = {2021},
}
@article{Azath2020,
   abstract = {In a software development process, effective cost estimation is the most challenging activity. Software effort estimation is a crucial part of cost estimation. Management cautiously considers the efforts and benefits of software before committing the required resources to that project or order for a contract. Unfortunately, it is difficult to measure such preliminary estimation, as it has only little information about the project at an early stage. In this paper, a new approach is proposed; this is based on reasoning by the soft computing approach to calculate the effort estimation of the software. In this approach, rules are generated based on the input dataset. These rules are then clustered for better estimation. In our proposed method, we use modified fuzzy C means for clustering the dataset. Once the clustering is done, various rules are obtained and these rules are given as the input to the neural network. Here, we modify the neural network by incorporating optimization algorithms. The optimization algorithms employed here are the artificial bee colony (ABC), modified cuckoo search (MCS), and hybrid ABC-MCS algorithms. Hence, we obtain three optimized sets of rules that are used for the effort estimation process. The performance of our proposed method is investigated using parameters such as the mean absolute relative error and mean magnitude of relative error.},
   author = {Hussain Azath and Marimuthu Mohanapriya and Somasundaram Rajalakshmi},
   doi = {10.1515/jisys-2017-0121},
   issue = {1},
   journal = {J. Intell. Syst},
   keywords = {Cost estimation,clustering,fuzzy,neural network},
   pages = {251-263},
   title = {Software Effort Estimation Using Modified Fuzzy C Means Clustering and Hybrid ABC-MCS Optimization in Neural Network},
   volume = {29},
   url = {https://doi.org/10.1515/jisys-2017-0121},
   year = {2020},
}
@web_page{IBM,
   title = {Conceptos básicos (redes neuronales) - Documentación de IBM},
   url = {https://www.ibm.com/docs/es/spss-modeler/SaaS\?topic=networks-basics-neural},
}
@article{Borracci2021,
   abstract = {Objective: The aim of this study was to develop, train, and test different neural network (NN) algorithm-based models to improve the Global Registry of Acute Coronary Events (GRACE) score performance to predict in-hospital mortality after an acute coronary syndrome. Methods: We analyzed a prospective database, including 40 admission variables of 1255 patients admitted with the acute coronary syndrome in a community hospital. Individual predictors included in GRACE score were used to train and test three NN algorithm-based models (guided models), namely: one-and two-hidden layer multilayer per-ceptron and a radial basis function network. Three extra NNs were built using the 40 admission variables of the entire database (unguided models). Expected mortality according to GRACE score was calculated using the logistic regression equation. Results: In terms of receiver operating characteristic area and negative predictive value (NPV), almost all NN algorithms outperformed logistic regression. Only radial basis function models obtained a better accuracy level based on NPV improvement , at the expense of positive predictive value (PPV) reduction. The independent normalized importance of variables for the best unguided NN was: creatinine 100\%, Killip class 61\%, ejection fraction 52\%, age 44\%, maximum creatine-kinase level 41\%, glycemia 40\%, left bundle branch block 35\%, and weight 33\%, among the top 8 predictors. Conclusions: Treatment of individual predictors of GRACE score with NN algorithms improved accuracy and discrimination power in all models with respect to the traditional logistic regression approach; nevertheless, PPV was only marginally enhanced. Unguided variable selection would be able to achieve better results in PPV terms. Resumen Objetivo: El objetivo fue desarrollar, entrenar y probar diferentes modelos basados en algoritmos de redes neuronales (RN) para mejorar el rendimiento del score del Registro Global de Eventos Coronarios Agudos (GRACE) para predecir la mortal-idad hospitalaria después de un síndrome coronario agudo. Métodos: Analizamos una base de datos prospectiva que incluía 40 variables de ingreso de 1255 pacientes con síndrome coronario agudo en un hospital comunitario. Las variables incluidas},
   author = {Raul A Borracci and Claudio C Higa and Graciana Ciambrone and Jimena Gambarte},
   doi = {10.24875/ACM.20000011},
   issue = {1},
   journal = {Arch Cardiol Mex},
   keywords = {Acute coronary syndrome,Artificial neural networks,Predictors,Risk stratification},
   pages = {58-65},
   title = {Treatment of individual predictors with neural network algorithms improves Global Registry of Acute Coronary Events score discrimination El tratamiento con redes neuronales de las variables del Global Registry of Acute Coronary mejora la discriminación del score Correspondence},
   volume = {91},
   url = {www.archivoscardiologia.com},
   year = {2021},
}
@article{Grazia2022,
   abstract = {La inteligencia artificial (IA) se manifiesta en algoritmos cuyo desempeño es difícil de predecir o explicar. Estos algoritmos se aplican a cuestiones de la vida cotidiana de los ciudadanos, como por ejemplo el otorgamiento de un préstamo bancario, y han empezado a utilizarse por parte del gobierno electrónico. Actualmente se investiga la aplicación de IA a todos los campos del conocimiento. En este trabajo se refieren brevemente algunos desarrollos en las ciencias de la información y se presentan algunos de los desafíos que plantea la aplicación de IA, como el sesgo y la opacidad. Frente a estos desafíos hay opiniones de la ética de la información, el movimiento de soware libre e investigaciones académicas para mejorar la explicabilidad de IA (XAI). Por último, se detalla sucintamente la estrategia de gobierno electrónico en Uruguay. Queda abierta la reflexión y, en particular, se recomienda la inclusión en la formación académica de estos temas en las carreras de bibliotecología. Palabras clave: Inteligencia artificial, Ética de la información, Explicabilidad, Gobierno electrónico, Uruguay. Abstract: Artificial intelligence (AI) manifests itself in algorithms whose performance is difficult to predict or explain. ese algorithms are applied to issues in the lives of citizens and have begun to be used by electronic government. e application of AI to all fields of knowledge is currently being investigated. Some developments in information science are briefly referred to in the note. Some of the challenges posed by the application of AI such as bias and opacity are presented. Facing these challenges are opinions from information ethics, the free soware movement, and academic research to improve the explainability of AI (XAI). Finally, the Electronic Government strategy in Uruguay is succinctly detailed.e reflection is open and in particular the inclusion of these topics in the academic training is recommended in our career. La inteligencia artificial (IA) es un área de la ciencia de computación que se relaciona con la matemática, la filosofía, la biología y la lingüística, entre otras, y que abarca distintos tipos de algoritmos para la resolución de problemas. Los algoritmos con los que lidiamos al realizar tareas cotidianas, como retirar dinero de un cajero, consisten en un procedimiento paso a paso de una secuencia de ejecución preestablecida. Sin embargo, los algoritmos de IA utilizan otros mecanismos y no se sabe a priori cómo será su ejecución ya que sus métodos son probabilísticos o económicos, lo cual les permite lidiar con información incompleta o incierta. Otra estrategia de IA para resolver problemas es la de representar el mundo de acuerdo a modelos, como las ontologías, que incorporan conceptos, propiedades y relaciones, y utilizan la lógica descriptiva para establecer axiomas que permiten razonar sobre el modelo. Los agentes o sistemas de hardware. soware, según Wooldridge \& Jennings (1995), tienen propiedades de autonomía, habilidad social, reactividad y proactividad. La autonomía es un factor importante ya que estos agentes pueden actuar en forma flexible sin la intervención de otros sistemas o personas para cumplir Palabra Clave, (La Plata), abril-septiembre 2022, vol. 11, n° 2, e159.},
   author = {Silvana Grazia and Temesio Vizoso},
   doi = {10.24215/18539912e159},
   issn = {1853-9912},
   keywords = {Artificial intelligence,E-government,Explainability,Explicabilidad,Gobierno electrónico,Information ethics,Inteligencia artificial,Uruguay,Ética de la información},
   title = {Reflexiones sobre la inteligencia artificial y la bibliotecología Reflections on artificial intelligence and librarianship},
   url = {https://doi.org/10.24215/18539912e159},
   year = {2022},
}
@article{Kang2020,
   author = {Da-Young Kang and Kyung-Jae Cho and Oyeon Kwon and Joon-myoung Kwon and Ki-Hyun Jeon and Hyunho Park and Yeha Lee and Jinsik Park and Byung-Hee Oh},
   doi = {10.1186/s13049-020-0713-4},
   issn = {1757-7241},
   issue = {1},
   journal = {Scandinavian Journal of Trauma, Resuscitation and Emergency Medicine},
   month = {12},
   pages = {4-5},
   title = {Artificial intelligence algorithm to predict the need for critical care in prehospital emergency medical services},
   volume = {28},
   year = {2020},
}
@article{Nagendran2020,
   author = {Myura Nagendran and Yang Chen and Christopher A Lovejoy and Anthony C Gordon and Matthieu Komorowski and Hugh Harvey and Eric J Topol and John P A Ioannidis and Gary S Collins and Mahiben Maruthappu},
   doi = {10.1136/bmj.m689},
   issn = {1756-1833},
   journal = {BMJ},
   month = {3},
   pages = {m689},
   title = {Artificial intelligence versus clinicians: systematic review of design, reporting standards, and claims of deep learning studies},
   year = {2020},
}
@article{Bioetica2022,
   abstract = {Resumo Este artigo explora vantagens e possíveis desafios bioéticos do uso da inteligência artificial em hospitais. A partir da identificação de desafios no desenvolvimento de sistemas dotados de inteligência artificial (fase pré-hospitalar) e na implementação e capacitação de equipes de saúde (fase hospitalar), analisa-se o papel da abordagem bioética no enfrentamento dessa situação, sobretudo dos comitês de bioética hospitalar. Desse modo, mediante a identificação de desafios de ordem individual – referentes à autonomia, consentimento e privacidade dos pacientes – e coletiva – como a sociedade em geral deve se portar diante das novas tecnologias –, observa-se o papel do Estado na proteção da privacidade do paciente no contexto de utilização da inteligência artificial. Em conclusão, considerando a vulnerabilidade humana perante a tecnologia, entende-se que a regulamentação é um instrumento que, junto com os princípios bioéticos, tenta minimizar os desafios do uso da inteligência artificial em hospitais.},
   author = {Revista Bioética and Heloá Da Conceição Nunes and Rita Miranda Coessens Guimarães and Luciana Dadalto},
   doi = {10.1590/1983-80422022301509PT},
   issn = {1983-8042},
   issue = {1},
   journal = {Revista Bioética},
   keywords = {Bioética,Hospitais,Inteligência artificial},
   month = {5},
   pages = {82-93},
   publisher = {Conselho Federal de Medicina},
   title = {Desafios bioéticos do uso da inteligência artificial em hospitais},
   volume = {30},
   url = {http://www.scielo.br/j/bioet/a/kG8vs4WHYKcGSrQVGwmrkTg/?lang=pt},
   year = {2022},
}
@article{Pang2017,
   abstract = {Background and objectives Highly accurate classification of biomedical images is an essential task in the clinical diagnosis of numerous medical diseases identified from those images. Traditional image classification methods combined with hand-crafted image feature descriptors and various classifiers are not able to effectively improve the accuracy rate and meet the high requirements of classification of biomedical images. The same also holds true for artificial neural network models directly trained with limited biomedical images used as training data or directly used as a black box to extract the deep features based on another distant dataset. In this study, we propose a highly reliable and accurate end-to-end classifier for all kinds of biomedical images via deep learning and transfer learning. Methods We first apply domain transferred deep convolutional neural network for building a deep model; and then develop an overall deep learning architecture based on the raw pixels of original biomedical images using supervised training. In our model, we do not need the manual design of the feature space, seek an effective feature vector classifier or segment specific detection object and image patches, which are the main technological difficulties in the adoption of traditional image classification methods. Moreover, we do not need to be concerned with whether there are large training sets of annotated biomedical images, affordable parallel computing resources featuring GPUs or long times to wait for training a perfect deep model, which are the main problems to train deep neural networks for biomedical image classification as observed in recent works. Results With the utilization of a simple data augmentation method and fast convergence speed, our algorithm can achieve the best accuracy rate and outstanding classification ability for biomedical images. We have evaluated our classifier on several well-known public biomedical datasets and compared it with several state-of-the-art approaches. Conclusions We propose a robust automated end-to-end classifier for biomedical images based on a domain transferred deep convolutional neural network model that shows a highly reliable and accurate performance which has been confirmed on several public biomedical image datasets.},
   author = {Shuchao Pang and Zhezhou Yu and Mehmet A. Orgun},
   doi = {10.1016/J.CMPB.2016.12.019},
   issn = {1872-7565},
   journal = {Computer methods and programs in biomedicine},
   keywords = {Computer*,Diagnostic Imaging*,MEDLINE,Machine Learning,Mehmet A Orgun,Models,NCBI,NIH,NLM,National Center for Biotechnology Information,National Institutes of Health,National Library of Medicine,Neural Networks,PubMed Abstract,Shuchao Pang,Theoretical,Zhezhou Yu,doi:10.1016/j.cmpb.2016.12.019,pmid:28254085},
   month = {3},
   pages = {283-293},
   pmid = {28254085},
   publisher = {Comput Methods Programs Biomed},
   title = {A novel end-to-end classifier using domain transferred deep convolutional neural networks for biomedical images},
   volume = {140},
   url = {https://pubmed.ncbi.nlm.nih.gov/28254085/},
   year = {2017},
}
@article{Astudillo2021,
   author = {Victor Astudillo and David Revelo},
   doi = {10.14482/inde.39.2.621.367},
   issn = {2145-9371},
   pages = {259-274},
   title = {Apoyo al diagnóstico de neumonía y detección de opacidades pulmonares usando segmentación de instancias semánticas en imágenes de rayos X de tórax},
   volume = {39},
   url = {https://doi.org/10.14482/inde.39.2.621.367},
   year = {2021},
}
@article{Dantas2021,
   abstract = {Aprendizaje de máquina para la predicción de reservas de carbono en un bosque tropical en el sureste de Brasil SUMMARY The increasing awareness of global climate change has drawn attention to the role of forests as mitigators of this process as they act as carbon sinks to the atmosphere. Understanding the process of carbon storage in forests and its drivers, as well as presenting consistent models for their estimation, is a current demand. In this sense, the aim of this study was to evaluate the performance of machine learning techniques: support vector machines (SVM) and to propose a new nonlinear model extracted from the training of an artificial neural network (ANN) in the modeling of above ground carbon stock in a secondary semideciduous forest. SVM and ANN construction and training process considered independent variables selected by stepwise: minimum DBH (diameter of breast height-1.3 m), maximum DBH, mean DBH, total height and number of trees, all by plot. SVM and the model extracted from ANN were applied to the data set intended for validation. Both techniques presented satisfactory performance in modeling carbon stock by plot, with homogeneous distribution and low dispersion of residues and predicted values close to those observed. Analysis criteria indicated superior performance of the model extracted from the artificial neural network, which presented a mean relative error of 6.94 \%, while the support vector machine presented 13.52 \%, combined with lower bias values and higher correlation between predictions and observations. Key words: artificial intelligence, artificial neural networks, support vector machines, forest biomass. RESUMEN La conciencia de la sociedad en relación a los cambios climáticos globales ha llamado la atención sobre el papel de los bosques como mitigadores de este proceso, ya que actúan como sumideros de carbono en la atmósfera. Comprender el proceso de almacenamiento de carbono en los bosques y sus determinantes, así como presentar modelos consistentes para su estimación es una demanda actual. En este sentido, el objetivo de este estudio fue evaluar el desempeño de las técnicas de máquina de vectores de soporte (SVM) y proponer un nuevo modelo no lineal extraído del entrenamiento de una red neuronal artificial (RNA) para modelar la cantidad de carbono sobre el suelo en un Bosque secundario estacional semideciduo. El proceso de construcción y entrenamiento de SVM y RNA consideró variables independientes seleccionadas por stepwise: DAP mínimo (diámetro de altura del pecho-1.3 m), DAP máximo, DAP promedio, altura total promedio y número de árboles, todo por unidad de muestreo. La SVM y el modelo extraído de la RNA se aplicaron al conjunto de datos para su validación. Ambas técnicas mostraron un desempeño satisfactorio en la modelación de la cantidad de carbono por unidad de muestreo, con distribución homogénea y baja dispersión de residuos y valores pronosticados cercanos a los observados. Los criterios de análisis utilizados indicaron un desempeño superior del modelo extraído de la red neuronal artificial, que presentó un error relativo promedio de 6.94 \%, mientras que la máquina de vectores de soporte presentó 13.52 \% junto con valores de sesgo más bajos y una mayor correlación entre predicciones. y observaciones. Palabras clave: inteligencia artificial, redes neuronales artificiales, máquinas de vectores de soporte, biomasa forestal.},
   author = {Daniel Dantas and Marcela De and Castro Nunes and Santos Terra and Luis Paulo and Baldissera Schorr and Natalino Calegario},
   doi = {10.4067/S0717-92002021000100131},
   issue = {1},
   journal = {BOSQUE},
   pages = {131-140},
   title = {Machine learning for carbon stock prediction in a tropical forest in Southeastern Brazil},
   volume = {42},
   year = {2021},
}
@article{Pena-Torres,
   abstract = {In this article, we study the relation extraction problem from Natural Language Processing (NLP) implementing a domain adaptation setting without external resources. We trained a Deep Learning (DL) model for Relation Extraction (RE), which extracts semantic relations in the biomedical domain. However, can the model be applied to different domains? The model should be adaptable to automatically extract relationships across different domains using the DL network. Completely training DL models in a short time is impractical because the models should quickly adapt to different datasets in several domains without delay. Therefore, adaptation is crucial for intelligent systems, where changing factors and unanticipated perturbations are common. In this study, we present a detailed analysis of the problem, as well as preliminary experimentation, results, and their evaluation. Resumen En este trabajo estudiamos el problema de extracción de relaciones del Procesamiento de Lenguaje Natural (PLN). Realizamos una configuración para la adaptación de dominio sin recursos externos. De esta forma, entrenamos un modelo con aprendizaje profundo (DL) para la extracción de relaciones (RE). El modelo permite extraer relaciones semánticas para el dominio biomédico. Sin embargo, ¿El modelo puede ser aplicado a diferentes dominios? El modelo debería adaptarse automáticamente para la extracción de relaciones entre diferentes dominios usando la red de DL. Entrenar completamente modelos DL en una escala de tiempo corta no es práctico, deseamos que los modelos se adapten rápidamente de diferentes conjuntos de datos con varios dominios y sin demora. Así, la adaptación es crucial para los sistemas inteligentes que operan en el mundo real, donde los factores cambiantes y las perturbaciones imprevistas son habituales. En este artículo, presentamos un análisis detallado del problema, una experimentación preliminar, resultados y la discusión acerca de los resultados. Palabras clave Extracción semántica, Aprendizaje profundo, Extracción de relaciones, Procesamiento de lenguaje natural.},
   author = {Jefferson A Peña-Torres and Raúl E Gutiérrez and Víctor A Bucheli and Fabio A González},
   doi = {10.22430/22565337.1483},
   issn = {2256-5337},
   keywords = {Deep Learning,Natural Language Processing,Relation Extraction,Semantic Extraction},
   pages = {49-62},
   title = {How to Adapt Deep Learning Models to a New Domain: The Case of Biomedical Relation Extraction Cómo adaptar un modelo de aprendizaje profundo a un nuevo dominio: el caso de la extracción de relaciones biomédicas How to Adapt Deep Learning Models to a New Domain: The Case of Biomedical Relation Extraction},
   volume = {22},
   url = {https://doi.org/10.22430/22565337.1483},
   year = {2019},
}
@report{Simonyan2015,
   abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3 × 3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisa-tion and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
   author = {Karen Simonyan and Andrew Zisserman},
   keywords = {()},
   title = {VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION},
   url = {http://www.robots.ox.ac.uk/},
   year = {2015},
}
@report{Fei-Fei2006,
   abstract = {Learning visual models of object categories notoriously requires hundreds or thousands of training examples. We show that it is possible to learn much information about a category from just one, or a handful, of images. The key insight is that, rather than learning from scratch, one can take advantage of knowledge coming from previously learned categories, no matter how different these categories might be. We explore a Bayesian implementation of this idea. Object categories are represented by probabilistic models. Prior knowledge is represented as a probability density function on the parameters of these models. The posterior model for an object category is obtained by updating the prior in the light of one or more observations. We test a simple implementation of our algorithm on a database of 101 diverse object categories. We compare category models learned by an implementation of our Bayesian approach to models learned from by Maximum Likelihood (ML) and Maximum A Posteriori (MAP) methods. We find that on a database of more than 100 categories, the Bayesian approach produces informative models when the number of training examples is too small for other methods to operate successfully.},
   author = {Li Fei-Fei and Rob Fergus and Pietro Perona},
   keywords = {Index Terms-Recognition,few images,learning,object categories,priors,unsupervised,variational inference},
   title = {One-Shot Learning of Object Categories},
   year = {2006},
}

@article{Itti2007,
   abstract = {Visual salience (or visual saliency) is the distinct subjective perceptual quality which makes some items in the world stand out from their neighbors and immediately grab our attention.},
   author = {Laurent Itti},
   doi = {10.4249/SCHOLARPEDIA.3327},
   issn = {1941-6016},
   issue = {9},
   journal = {Scholarpedia},
   pages = {3327},
   publisher = {Scholarpedia},
   title = {Visual salience},
   volume = {2},
   url = {http://www.scholarpedia.org/article/Visual_salience},
   year = {2007},
}

   abstract = {Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark (Krizhevsky et al., 2012). However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we address both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. Used in a diagnostic role, these visualizations allow us to find model architec-tures that outperform Krizhevsky et al. on the ImageNet classification benchmark. We also perform an ablation study to discover the performance contribution from different model layers. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.},
   author = {Matthew D Zeiler and Rob Fergus},
   month = {11},
   title = {Visualizing and Understanding Convolutional Networks},
   url = {https://arxiv.org/abs/1311.2901v3},
   year = {2013},
}
@ELECTRONIC{Stanford,
   author = {Standford Vision Lab and Universidad de Stanford and Universidad de Princeton},
   title = {ImageNet},
   url = {https://www.image-net.org/},
}
@article{PuertaBarrera2015,
   abstract = {Background: The sun is a natural source of electromagnetic radiation, upon which are found the ultraviolet (UV) rays, where only the types A and B are able to irradiate over the surface of the Earth in different proportions. Although the sun helps human skin in the formation of vitamin D, the minerali-zation of bones, and absorption of calcium and phosphorus in the organism, it can cause damage on the skin by prolonged exposure to UV radiation, generating adverse effects on human health like erythema formation, photo-toxicity, photo-allergy, idiopathic lesions, and photo-dermatitis, among others. This paper, shows the results of developing a prediction system of the exposure time of a person to UV rays coming from the sun, which can cause erythema on human skin, using the standards in UV index and the dose limits of radiation allowed for phototypes I and II, aiming to foresee the generation of these kind of lesions. This was made by the implementation of artificial intelligence algorithms like Deep Belief Networks and Backpropagation, based in the Deep Learning technique. These algorithms use as training parameters for the neural network, the meteorological data such as the sky clearness index, the radiation on the horizontal surface and average air temperature, supplied by the National Aeronautics and Space Administration (NASA). With the data, a neural network aiming to foresee the UV index for the following year of the data input was trained, in addition some mathematical regressions were applied allowing in this way, to obtain an approach to the behavior of the UV index along the day. Likewise, this information was used to estimate the maximum time of sun exposure, for the period of time contained between 6:00 a.m. and 6:00 p.m. This paper, also presents some conclusions based in the results found, which try to establish some important considerations in order to implement the neural networks.},
   author = {Juan Felipe PUERTA BARRERA and Ing Mecatrónica and Dario Amaya Hurtado and Robinson Jimenez Moreno},
   doi = {10.17533/udea.vitae.v22n3a03},
   issue = {3},
   pages = {188-196},
   title = {PREDICTION SYSTEM OF ERYTHEMAS FOR PHOTOTYPES I AND II, USING DEEP-LEARNING SISTEMA DE PREDICCIÓN DE ERITEMA PARA FOTOTIPO I Y II, UTILIZANDO DEEP-LEARNING},
   volume = {22},
   year = {2015},
}
@article{Wintermark2013,
   abstract = {Stroke is a leading cause of death and disability worldwide. Imaging plays a critical role in evaluating patients suspected of acute stroke and transient ischemic attack, especially before initiating treatment. Over the past few decades, major advances have occurred in stroke imaging and treatment, including Food and Drug Administration approval of recanalization therapies for the treatment of acute ischemic stroke. A wide variety of imaging techniques has become available to assess vascular lesions and brain tissue status in acute stroke patients. However, the practical challenge for physicians is to understand the multiple facets of these imaging techniques, including which imaging techniques to implement and how to optimally use them, given available resources at their local institution. Important considerations include constraints of time, cost, access to imaging modalities, preferences of treating physicians, availability of expertise, and availability of endovascular therapy. The choice of which imaging techniques to employ is impacted by both the time urgency for evaluation of patients and the complexity of the literature on acute stroke imaging. Ideally, imaging algorithms should incorporate techniques that provide optimal benefit for improved patient outcomes without delaying treatment. S troke is a leading cause of death and disability worldwide.},
   author = {M Wintermark and P C Sanelli and G W Albers and J Bello and C Derdeyn and S W Hetts and M H Johnson and C Kidwell and M H Lev and D S Liebeskind and H Rowley and P W Schaefer and J L Sunshine and G Zaharchuk and C C Meltzer},
   doi = {10.3174/ajnr.A3690},
   title = {Imaging Recommendations for Acute Stroke and Transient Ischemic Attack Patients: A Joint Statement by the American Society of Neuroradiology, the American College of Radiology, and the Society of NeuroInterventional Surgery},
   url = {http://dx.doi.org/10.3174/ajnr.A3690},
   year = {2013},
}
@article{Garcia2019,
   abstract = {<p>Resumen: El ataque cerebrovascular (ACV) agudo es la segunda causa de muerte en el mundo y genera costos elevados en su tratamiento y recuperación, así como un gran impacto socioeconómico, pues es la principal causa de discapacidad a largo plazo. Si bien la tomografía axial computarizada (TAC) cerebral simple sigue siendo la imagen recomendada por las guías internacionales para la evaluación inicial y toma de decisiones sobre el manejo del paciente con sospecha de ACV, en los últimos años ha habido extraordinarios avances en el diagnóstico oportuno y temprano del ACV con nuevas herramientas que van desde la estandarización de la angiotomografía cerebral como uno de los estudios principales en el enfoque inicial hasta el uso de técnicas de perfusión por tomografía y resonancia magnética (RM) cerebral, que permiten establecer el núcleo del infarto y el área circundante potencialmente salvable, por lo que es posible ofrecer terapias que brindan al paciente funcionalidad y calidad de vida a mediano y largo plazo. Teniendo en cuenta lo anterior, es vital actualizar los métodos diagnósticos actuales disponibles en el país y las distintas terapias disponibles, según sea el caso de cada paciente, para el ACV isquémico agudo, con un enfoque clínico práctico y aplicable al escenario actual de salud en Colombia.</p>},
   author = {Carolina García Alfonso and Andrea Estefania Martínez Reyes and Valentina García and Andres Ricaurte Fajardo and Isabel Torres and Juliana Coral Casas},
   doi = {10.11144/Javeriana.umed60-3.actu},
   issn = {2011-0839},
   issue = {3},
   journal = {Universitas Médica},
   month = {6},
   pages = {1-17},
   title = {Actualización en diagnóstico y tratamiento del ataque cerebrovascular isquémico agudo},
   volume = {60},
   year = {2019},
}
@article{Molina2018,
   author = {Jessica Molina Seguin and Ana B. Vena and Laura Colàs Campàs and Ikram Benalbdelhak and Francisco Purroy García},
   doi = {10.33588/rn.6610.2017377},
   issn = {0210-0010},
   issue = {10},
   journal = {Revista de Neurología},
   pages = {325},
   title = {Revisión sistemática de las características y pronóstico de los sujetos que sufren un ictus criptogénico no lacunar de mecanismo embólico},
   volume = {66},
   year = {2018},
}
@article{Piloto2020,
   author = {Anabel Piloto Cruz and Birsy Suarez Rivero and Juan Carlos Echevarría Parlay},
   journal = {Archivos del Hospital Universitario General Calixto García},
   title = {Diagnóstico clínico y tomográfico en la enfermedad cerebrovascular},
   url = {http://www.revcalixto.sld.cu/index.php/ahcg/rt/printerFriendly/529/537},
   year = {2020},
}
@article{Radu2017,
   author = {Răzvan Alexandru Radu and Elena Oana Terecoasă and Ovidiu Alexandru Băjenaru and Cristina Tiu},
   doi = {10.1016/j.clineuro.2017.05.019},
   issn = {03038467},
   journal = {Clinical Neurology and Neurosurgery},
   month = {8},
   pages = {93-106},
   title = {Etiologic classification of ischemic stroke: Where do we stand?},
   volume = {159},
   url = {https://linkinghub.elsevier.com/retrieve/pii/S030384671730149X},
   year = {2017},
}
@article{Adams1993,
   abstract = {<p>The etiology of ischemic stroke affects prognosis, outcome, and management. Trials of therapies for patients with acute stroke should include measurements of responses as influenced by subtype of ischemic stroke. A system for categorization of subtypes of ischemic stroke mainly based on etiology has been developed for the Trial of Org 10172 in Acute Stroke Treatment (TOAST).</p>},
   author = {H P Adams and B H Bendixen and L J Kappelle and J Biller and B B Love and D L Gordon and E E Marsh},
   doi = {10.1161/01.STR.24.1.35},
   issn = {0039-2499},
   issue = {1},
   journal = {Stroke},
   month = {1},
   pages = {35-41},
   title = {Classification of subtype of acute ischemic stroke. Definitions for use in a multicenter clinical trial. TOAST. Trial of Org 10172 in Acute Stroke Treatment.},
   volume = {24},
   url = {https://www.ahajournals.org/doi/10.1161/01.STR.24.1.35},
   year = {1993},
}
@web_page{WHO,
   author = {Wold Health Organization},
   title = {About WHO},
   url = {https://www.who.int/es/about/frequently-asked-questions},
}
@article{Curioso2020,
   abstract = {Tuberculosis remains an urgent issue on the urban health agenda, especially in low-and middle-income countries. There is a need to develop and implement innovative and effective solutions in the tuberculosis diagnostic process. In this article, We describe the importance of artificial intelligence as a strategy to address tuberculosis control, particularly by providing timely diagnosis. Besides technological factors, the role of socio-technical, cultural and organizational factors is emphasized. The eRx tool involving deep learning algorithms and specifically the use of convolutional neural networks is presented as a case study. eRx is a promising artificial intelligence-based tool for the diagnosis of tuberculosis; which comprises a variety of innovative techniques involving remote X-ray analysis for suspected tuberculosis cases. In-novations based on artificial intelligence tools can optimize the diagnostic process for tuberculosis and other communicable diseases.},
   author = {Walter H. Curioso and Maria J. Brunette},
   doi = {10.17843/RPMESP.2020.373.5585},
   issn = {17264642},
   issue = {3},
   journal = {Revista Peruana de Medicina Experimental y Salud Publica},
   keywords = {Artificial Intelligence,Diagnosis,Inventions,Peru (source: MeSH NLM),Tuberculosis,Urban Health},
   month = {7},
   pages = {554-558},
   pmid = {33295561},
   publisher = {Instituto Nacional de Salud},
   title = {Artificial intelligence and innovation to optimize the tuberculosis diagnostic process},
   volume = {37},
   year = {2020},
}
@ELECTRONIC{ServicioSaludNuble,
   author = {Servicio de Salud de Ñuble},
   month = {10},
   title = {El 80\% de los casos de ataque cerebrovascular se pueden prevenir},
   url = {https://www.serviciodesaludnuble.cl/sitio/el-80-de-los-casos-de-ataque-cerebrovascular-se-pueden-prevenir/},
   year = {2018},
}
@article{Cabrera2020,
   abstract = {El cerebro es el órgano más sensible del cuerpo. Distinción que exige para su funcionamiento del aporte constante de oxígeno y nutrientes, pues son elementos que lo conservan vivo y activo. Con el objetivo de caracterizar a los pacientes con enfermedad cerebrovascular de los consultorios médicos de la familia 9, 10 y 11 del Policlínico 13 de Marzo en Bayamo, de Enero a Julio de 2019, se realizó un estudio descriptivo y retroprospectivo, de corte transversal de 17 pacientes con enfermedad cerebrovascular. Los datos primarios fueron extraídos de las historias clínicas y registros de los consultorios y plasmados en una planilla elaborada a los efectos y se realiza una base de datos en Excel Microsoft 2010. Entre las variables de interés figuraron edad, sexo, antecedentes personales, clasificación, área de salud y secuela. Al relacionar, según el sexo de los pacientes con enfermedad cerebrovascular, se apreció un predominio en el sexo femenino 9 (52,94 \%) y el grupo etario más afectado fue el de 78-92(41.18\%), entre los antecedentes personales asociados, se presentó en el 94.11\% de los pacientes la hipertensión, el 76.47 \% presentó el tipo isquémico. El 41,18\% de los pacientes con enfermedad cerebrovascular pertenecen al área de salud del CMF 9. El 41,18\% de los pacientes presentaron como secuela la hemiplejia derecha, ya sea sola o con otra afectación. Las características principales de los pacientes con ECV en su mayoría resultaron féminas mayores de 70 años, hipertensas, sufrieron el tipo de accidentes isquémico y tienen como secuelas hemiplejia derecha.},
   author = {Evelyn Cabrera Rodríguez and Aleida Santamarina Fernández and Alianok González González and Misleidy Garcés Camejo and Yanet Fonseca Viltres},
   issn = {1028-4818},
   journal = {Multimed},
   title = {Características de los pacientes con enfermedad cerebrovascular},
   url = {http://scielo.sld.cu/scielo.php?script=sci_arttext\&pid=S1028-48182020000200352},
   year = {2020},
}
@article{Ortiz-Galeano2020,
   author = {Ignacio Ortiz-Galeano and Natalia Eloísa Fernández Balmaceda and Alan Flores},
   doi = {10.18004/rvspmi/2312-3893/2020.07.01.50-055},
   issue = {1},
   journal = {Revista Virtual de la Sociedad Paraguaya de Medicina Interna},
   month = {3},
   pages = {50-55},
   publisher = {Instituto de Investigaciones en Ciencias de la Salud},
   title = {Cardiovascular risk factors in patients with stroke},
   volume = {7},
   year = {2020},
}
@article{Gaudiano2019,
   abstract = {Epidemiológica del ataque cerebro vascular en un hospital universitario Epidemiological of cerebrovascular attack in a university hospital Epidemiologia do ataque cerebrovascular em hospital universitário Resumen: Introducción: El ataque cerebro vascular es una enfermedad prevalente en nuestro medio con elevada morbimortalidad. El Hospital Pasteur es un centro de tercer nivel, que asiste un elevado número de pacientes con esta patología. Conocer los datos epidemiológicos de esta afección permitirá desarrollar medidas de promoción de salud y prevención primaria. Identificar la forma de presentación clínica y los algoritmos de estudio, permitirán un adecuado diagnóstico, tratamiento precoz y desarrollo de medidas de prevención secundaria. Objetivos: Conocer las características sociodemográficas de la población con diagnóstico de ataque cerebro vascular o accidente isquémico transitorio asistidas en las salas de medicina del Hospital Pasteur, los factores de riesgo asociados, las formas de presentación clínica y precisar si se cumplió con el algoritmo diagnóstico propuesto. Métodos y procedimiento: Estudio descriptivo observacional y transversal realizado en el Hospital Pasteur. La población de estudio fueron pacientes adultos ingresados en sala de medicina con diagnóstico de ataque cerebro vascular o accidente isquémico transitorio que presentaron el evento durante su internación, en el periodo comprendido entre Julio y Setiembre de 2018. Resultados y discusión: Se recabaron datos de 29 pacientes, 20 de sexo femenino. La media de edad fue de 70.34 años. La naturaleza isquémica fue la más prevalente. Los factores de riesgo cardiovascular más frecuentes fueron HTA, sedentarismo, dislipemia y tabaquismo. La principal forma de presentación fue síndrome piramidal. Se cumplió con el algoritmo diagnostico en todos los pacientes. Conclusión: Conocer los factores de riesgo, naturaleza y forma de presentación clínica permite elaborar estrategias de prevención primaria y secundaria para el abordaje integral de estos pacientes, intentando así reducir la incidencia y secuelas de esta enfermedad. Palabras clave: ACV, AIT, factores de riesgo cardiovascular, HTA. Abstract: Introduction: Acute ischemic stroke is a prevalent condition in our working environment, with high morbility and mortality. Hospital Pasteur is a tertiary level institution, which assists an elevated number of patients with acute ischemic stroke. Getting to know its epidemiologic characteristics will enable the development of health promotion and primary prevention measures. Identifying its clinical presentation form and applying validated study algorithms will allow for a proper diagnosis, early treatment and development of secondary prevention measures. Objectives: To study the sociodemographic characteristics of patients diagnosed with acute ischemic stroke or transient ischemic attack assisted in Hospital Pasteur´s Internal Medicine wards, their associated risk factors, clinical presentation and to determine whether the proposed study algorithm was followed. Methodology and procedure: This is a descriptive, observational and transversal study which took place at Hospital Pasteur. The population consisted of adult patients admitted to Internal Medicine wards with the diagnosis of acute ischemic stroke, transient ischemic attack or who presented the event during their stay, between the months of July and September 2018. Results and discussion: The data of 29 patientes was obtained; 20 were female. The mean age was 70.34 years. Ischemic nature was the most prevalent. The most frequent risk factors were arterial hypertension, sedentary lifestyle, dyslipidemia and smoking. Pyramidal syndrome was the most common clinical presentation. A study algorithm was followed in all patients. Conclusion: Getting to know the risk factors, nature and clinical presentation form of AIS and TIA allows for the creation of primary and secondary},
   author = {Javier Gaudiano and Diego Graña and Mabel Goñi and Virginia Colina and Andrea Cosentino and Romina Pensado and Victoria Ruglio and Magali Scaron and Leticia Vidart and Javier Gaudiano and Diego Graña and Mabel Goñi and Virginia Colina and Andrea Cosentino and Romina Pensado and Victoria Ruglio and Magali Scaron and Leticia Vidart},
   doi = {10.26445/04.02.1},
   issn = {2393-6797},
   issue = {2},
   journal = {Revista Uruguaya de Medicina Interna },
   month = {7},
   pages = {24-31},
   publisher = {Sociedad de Medicina Interna del Uruguay},
   title = {Epidemiológica del ataque cerebro vascular en un hospital universitario},
   volume = {4},
   url = {http://www.scielo.edu.uy/scielo.php?script=sci_arttext\&pid=S2393-67972019000200024\&lng=es\&nrm=iso\&tlng=es http://www.scielo.edu.uy/scielo.php?script=sci_abstract\&pid=S2393-67972019000200024\&lng=es\&nrm=iso\&tlng=es},
   year = {2019},
}
@article{Garcia-Yepes2020,
   abstract = {The counterfort retaining wall is one of the most frequent structures used in civil engineering. In this structure, optimization of cost and CO2 emissions are important. The first is relevant in the competitiveness and efficiency of the company, the second in environmental impact. From the point of view of computational complexity, the problem is challenging due to the large number of possible combinations in the solution space. In this article, a k-means cuckoo search hybrid algorithm is proposed where the cuckoo search metaheuristic is used as an optimization mechanism in continuous spaces and the unsupervised k-means learning technique to discretize the solutions. A random operator is designed to determine the contribution of the k-means operator in the optimization process. The best values, the averages, and the interquartile ranges of the obtained distributions are compared. The hybrid algorithm was later compared to a version of harmony search that also solved the problem. The results show that the k-mean operator contributes significantly to the quality of the solutions and that our algorithm is highly competitive, surpassing the results obtained by harmony search.},
   author = {José García and Victor Yepes and José V. Martí},
   doi = {10.3390/MATH8040555},
   issn = {22277390},
   issue = {4},
   journal = {Mathematics},
   keywords = {CO2 emission,Cuckoo search,Earth-retaining walls,K-means,Optimization},
   month = {4},
   publisher = {MDPI AG},
   title = {A hybrid k-means cuckoo search algorithm applied to the counterfort retaining walls problem},
   volume = {8},
   year = {2020},
}
@article{Vega-Alvarado,
   author = {Eduardo Vega-Alvarado and Edgar Alfredo Portilla-Flores and G. A. Muñoz-Hernández and Efren Mezura-Montes and G. Sepúlveda-Cervantes and P. Bautista-Camino},
   doi = {10.23967/j.rimni.2017.5.002},
   issn = {02131315},
   issue = {2},
   journal = {Revista Internacional de Métodos Numéricos para Cálculo y Diseño en Ingeniería},
   month = {5},
   title = {Un algoritmo memético basado en la colonia artificial de abejas para síntesis óptima de mecanismos},
   volume = {33},
   year = {2017},
}
@article{Kattenborn2021,
   abstract = {Identifying and characterizing vascular plants in time and space is required in various disciplines, e.g. in forestry, conservation and agriculture. Remote sensing emerged as a key technology revealing both spatial and temporal vegetation patterns. Harnessing the ever growing streams of remote sensing data for the increasing demands on vegetation assessments and monitoring requires efficient, accurate and flexible methods for data analysis. In this respect, the use of deep learning methods is trend-setting, enabling high predictive accuracy, while learning the relevant data features independently in an end-to-end fashion. Very recently, a series of studies have demonstrated that the deep learning method of Convolutional Neural Networks (CNN) is very effective to represent spatial patterns enabling to extract a wide array of vegetation properties from remote sensing imagery. This review introduces the principles of CNN and distils why they are particularly suitable for vegetation remote sensing. The main part synthesizes current trends and developments, including considerations about spectral resolution, spatial grain, different sensors types, modes of reference data generation, sources of existing reference data, as well as CNN approaches and architectures. The literature review showed that CNN can be applied to various problems, including the detection of individual plants or the pixel-wise segmentation of vegetation classes, while numerous studies have evinced that CNN outperform shallow machine learning methods. Several studies suggest that the ability of CNN to exploit spatial patterns particularly facilitates the value of very high spatial resolution data. The modularity in the common deep learning frameworks allows a high flexibility for the adaptation of architectures, whereby especially multi-modal or multi-temporal applications can benefit. An increasing availability of techniques for visualizing features learned by CNNs will not only contribute to interpret but to learn from such models and improve our understanding of remotely sensed signals of vegetation. Although CNN has not been around for long, it seems obvious that they will usher in a new era of vegetation remote sensing.},
   author = {Teja Kattenborn and Jens Leitloff and Felix Schiefer and Stefan Hinz},
   doi = {10.1016/J.ISPRSJPRS.2020.12.010},
   issn = {0924-2716},
   journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
   keywords = {Convolutional Neural Networks (CNN),Deep learning,Earth observation,Plants,Remote sensing,Vegetation},
   month = {3},
   pages = {24-49},
   publisher = {Elsevier},
   title = {Review on Convolutional Neural Networks (CNN) in vegetation remote sensing},
   volume = {173},
   year = {2021},
}
@web_page{pagACVDiabetico,
   title = {Desarrollo de un algoritmo con redes neuronales para la predicción de ACV en pacientes diabéticos},
   url = {https://repositorio.autonoma.edu.pe/handle/20.500.13067/1522},
}
@article{Anis2019,
   abstract = {Hospitals take possession of daily large amounts of data of their patients who suffer from various illnesses, including stroke, and the lack of analytical tools used to obtain information in that regard, has made it difficult for physicians and paramedics to gain knowledge. In order to address this issue, predictive analytics serves to predict the type of stroke disease beforehand hence the treatment actions can be carried out early and more appropriately to avoid worsening the patients' condition status. In this research, we presented a model for predicting stroke solely based on the patients' medical record. The model was built by using artificial neural network to produce an estimation of the type of stroke whether it gets any worse than the initial diagnosis. Prediction analysis using Artificial Neural Network method possessed accuracy of 95.15%.},
   author = {Anis Fitri Nur Masruriyah and Taufik Djatna and Medria Kusuma Dewi Hardhienata and Hanny Hikmayanti Handayani and Deden Wahiddin},
   doi = {10.1109/ICIC47613.2019.8985716},
   isbn = {9781728122076},
   journal = {Proceedings of 2019 4th International Conference on Informatics and Computing, ICIC 2019},
   keywords = {Artificial Neural Network,Data Mining,Health Analytics,Stroke Diseases},
   month = {10},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Predictive Analytics For Stroke Disease},
   year = {2019},
}
@article{clasificacionYRegresionTree,
   abstract = {The 1984 monograph, “CART: Classiﬁcation and Regression Trees,” coauthored by
Leo Breiman, Jerome Friedman, Richard Olshen, and Charles Stone (BFOS), represents a major milestone in the evolution of artiﬁcial intelligence, machine learning,
nonparametric statistics, and data mining. The work is important for the comprehensiveness of its study of decision trees, the technical innovations it introduces, its
sophisticated examples of tree-structured data analysis, and its authoritative treatment
of large sample theory for trees. Since its publication the CART monograph has been
cited some 3000 times according to the science and social science citation indexes;
Google Scholar reports about 8,450 citations. CART citations can be found in almost
any domain, with many appearing in ﬁelds such as credit risk, targeted marketing, ﬁnancial markets modeling, electrical engineering, quality control, biology, chemistry,
and clinical medical research. CART has also strongly inﬂuenced image compressionvia tree-structured vector quantization. This brief account is intended to introduce
CART basics, touching on the major themes treated in the CART monograph, and to
encourage readers to return to the rich original source for technical details, discussions revealing the thought processes of the authors, and examples of their analytical
style.},
   doi = {10.1201/9781420089653-17/CART-CLASSI},
   journal = {The Top Ten Algorithms in Data Mining},
   month = {12},
   pages = {193-216},
   publisher = {Chapman and Hall/CRC},
   title = {CART: Classiﬁcation and Regression Trees},
   year = {2020},
}
@article{Vembandasamy2015,
   abstract = {Health care is an inevitable task to be done in human life. Health concern business has become a notable field in the wide spread area of medical science. Health care industry contains large amount of data and hidden information. Effective decisions are made with this hidden information by applying dataminnig techniques. Several tests are done in the detection of cardiovascular diseases in the patient; however with datamining these tests could be reduced. But there is a lack of analysing tool to provide effective test results with the hidden information, so a system is developed using data mining algorithms for classifying the data and to detect the heart diseases. Datamining acts as a solution for many healthcare problems. Naïve bayes algorithm is one such datamining technique which serves in the diagnosis of heart diseases patient. This paper analyse few parameters and predicts heart diseases, there by suggests a heart diseases prediction system (HDPS) based on the datamining approaches.},
   author = {K Vembandasamy and R Sasipriya and E Deepa - International Journal of and undefined 2015},
   issue = {9},
   journal = {ijiset.com},
   keywords = {datamining,healthcare system,heart diseases,heart diseases prediction system,naïve bayes algorithm},
   title = {Heart diseases detection using Naive Bayes algorithm},
   volume = {2},
   url = {https://www.ijiset.com/vol2/v2s9/IJISET\_V2\_I9\_54.pdf},
   year = {2015},
}
@article{ComparativeStudy,
   author = {SD Jadhav and HP Channe - Journal of Science and Research (IJSR) and undefined 2016},
   journal = {academia.edu},
   title = {Comparative study of K-NN, naive Bayes and decision tree classification techniques},
   url = {https://www.academia.edu/download/78177629/68c263ee197a292df5b74b58c8c55df9f9ca.pdf},
}
@article{and2006,
   abstract = {The naive Bayes classifier continues to be a popular learning algorithm for data mining applications due to its simplicity and linear run-time. Many enhancements to the basic algorithm have been proposed to help mitigate its primary weakness-the assumption that attributes are independent given the class. All of them improve the performance of naive Bayes at the expense (to a greater or lesser degree) of execution time and/or simplicity of the final model. In this paper we present a simple filter method for setting attribute weights for use with naive Bayes. Experimental results show that naive Bayes with attribute weights rarely degrades the quality of the model compared to standard naive Bayes and, in many cases, improves it dramatically. The main advantages of this method compared to other approaches for improving naive Bayes is its run-time complexity and the fact that it maintains the simplicity of the final model.},
   author = {M Hall - International conference on innovative techniques and and undefined 2006},
   journal = {Springer},
   title = {A decision tree-based attribute weighting filter for naive Bayes},
   url = {https://link.springer.com/chapter/10.1007/978-1-84628-663-6_5},
   year = {2006},
}
@article{Teknomo2015,
   abstract = {Human gait analysis is used to indirectly monitor the rehabilitation of patients affected by diseases or to directly monitor patients under orthotic care. Visualization of gait patterns on the instrument are used to capture the data. In this study, we created a mobile application that serves as a wireless sensor to capture movement through a smartphone accelerometer. The application was used to collect gait data from two groups (able-bodied and unilateral transtibial amputees). Standard gait activities such as walking, running and climbing, including non-movement, sitting were captured, stored and analyzed. This paper discusses different visualization techniques that can be derived from accelerometer data. Removing gravity data, accelerometer data can be transformed into distribution data using periodicity; features were derived from histograms. Decision tree analysis shows that only three significant features are necessary to classify subject activity, namely: average of minimum peak values, student t-statistics of minimum peak values and mode of maximum peak values. We found that the amputee group had a higher acceleration and a lower skewness period between peaks of accelerations than the able-bodied group.},
   author = {Kardi Teknomo and Maria Regina Estuar},
   doi = {10.15446/RCE.V37N2SPE.47951},
   issn = {01201751},
   issue = {2},
   journal = {Revista Colombiana de Estadistica},
   keywords = {Decision tree analysis,Feature selection,Gait monitoring,Transtibial amputees,Wireless sensors},
   pages = {471-488},
   publisher = {Universidad Nacional de Colombia},
   title = {Visualización de patrones de paso de individuos con y sin discapacidad con el uso de acelerometría en teléfonos inteligentes},
   volume = {37},
   year = {2015},
}
@article{Shafe,
   author = {G Shafer - Statistical Review/Revue Internationale de Statistique and undefined 1985},
   journal = {JSTOR},
   title = {Conditional probability},
   url = {https://www.jstor.org/stable/1402890},
}
@article{Stoltzfus2011,
   abstract = {Regression techniques are versatile in their application to medical research because they can measure associations, predict outcomes, and control for confounding variable effects. As one such technique, logistic regression is an efficient and powerful way to analyze the effect of a group of independent variables on a binary outcome by quantifying each independent variable's unique contribution. Using components of linear regression reflected in the logit scale, logistic regression iteratively identifies the strongest linear combination of variables with the greatest probability of detecting the observed outcome. Important considerations when conducting logistic regression include selecting independent variables, ensuring that relevant assumptions are met, and choosing an appropriate model building strategy. For independent variable selection, one should be guided by such factors as accepted theory, previous empirical investigations, clinical considerations, and univariate statistical analyses, with acknowledgement of potential confounding variables that should be accounted for. Basic assumptions that must be met for logistic regression include independence of errors, linearity in the logit for continuous variables, absence of multicollinearity, and lack of strongly influential outliers. Additionally, there should be an adequate number of events per independent variable to avoid an overfit model, with commonly recommended minimum "rules of thumb" ranging from 10 to 20 events per covariate. Regarding model building strategies, the three general types are direct/standard, sequential/hierarchical, and stepwise/statistical, with each having a different emphasis and purpose. Before reaching definitive conclusions from the results of any of these methods, one should formally quantify the model's internal validity (i.e., replicability within the same data set) and external validity (i.e., generalizability beyond the current sample). The resulting logistic regression model's overall fit to the sample data is assessed using various goodness-of-fit measures, with better fit characterized by a smaller difference between observed and model-predicted values. Use of diagnostic statistics is also recommended to further assess the adequacy of the model. Finally, results for independent variables are typically reported as odds ratios (ORs) with 95\% confidence intervals (CIs). © 2011 by the Society for Academic Emergency Medicine.},
   author = {Jill C. Stoltzfus},
   doi = {10.1111/J.1553-2712.2011.01185.X},
   issn = {1553-2712},
   issue = {10},
   journal = {Academic Emergency Medicine},
   month = {10},
   pages = {1099-1104},
   pmid = {21996075},
   title = {Logistic Regression: A Brief Primer},
   volume = {18},
   url = {https://onlinelibrary.wiley.com/doi/full/10.1111/j.1553-2712.2011.01185.x https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1553-2712.2011.01185.x https://onlinelibrary.wiley.com/doi/10.1111/j.1553-2712.2011.01185.x},
   year = {2011},
}
@web_page{Minsal2022,
   abstract = {En Chile, el año 2021 hubo 29.542 egresos hospitalarios por ACV y esta enfermedad fue la segunda causa de mortalidad, después de las enfermedades isquémicas del corazón, sin considerar la pandemia por SARS-CoV-2. Se registraron 7.501 defunciones por ACV ese mismo año, lo que equivale a 1 muerte cada 72 minutos.},
   author = {Chile Ministerio de Salud},
   title = {Ataque Cerebrovascular - Ministerio de Salud - Gobierno de Chile},
   url = {https://www.minsal.cl/ataque\_cerebral/},
   year = {2022},
}
@article{Heo2019,
   abstract = {Background and Purpose— The prediction of long-term outcomes in ischemic stroke patients may be useful in treatment decisions. Machine learning techniques are being increasingly adapted for use in ...},
   author = {Joon Nyung Heo and Jihoon G. Yoon and Hyungjong Park and Young Dae Kim and Hyo Suk Nam and Ji Hoe Heo},
   doi = {10.1161/STROKEAHA.118.024293},
   issn = {15244628},
   issue = {5},
   journal = {Stroke},
   keywords = {cerebral infarction,machine learning,medical decision making,neural networks,stroke},
   month = {5},
   pages = {1263-1265},
   pmid = {30890116},
   publisher = {
Lippincott Williams \& Wilkins
Hagerstown, MD
},
   title = {Machine Learning–Based Model for Prediction of Outcomes in Acute Stroke},
   volume = {50},
   url = {https://www.ahajournals.org/doi/abs/10.1161/STROKEAHA.118.024293},
   year = {2019},
}
@article{Scrutinio2020,
   abstract = {Stroke is among the leading causes of death and disability worldwide. Approximately 20–25\% of stroke survivors present severe disability, which is associated with increased mortality risk. Prognostication is inherent in the process of clinical decision-making. Machine learning (ML) methods have gained increasing popularity in the setting of biomedical research. The aim of this study was twofold: assessing the performance of ML tree-based algorithms for predicting three-year mortality model in 1207 stroke patients with severe disability who completed rehabilitation and comparing the performance of ML algorithms to that of a standard logistic regression. The logistic regression model achieved an area under the Receiver Operating Characteristics curve (AUC) of 0.745 and was well calibrated. At the optimal risk threshold, the model had an accuracy of 75.7\%, a positive predictive value (PPV) of 33.9\%, and a negative predictive value (NPV) of 91.0\%. The ML algorithm outperformed the logistic regression model through the implementation of synthetic minority oversampling technique and the Random Forests, achieving an AUC of 0.928 and an accuracy of 86.3\%. The PPV was 84.6\% and the NPV 87.5\%. This study introduced a step forward in the creation of standardisable tools for predicting health outcomes in individuals affected by stroke.},
   author = {Domenico Scrutinio and Carlo Ricciardi and Leandro Donisi and Ernesto Losavio and Petronilla Battista and Pietro Guida and Mario Cesarelli and Gaetano Pagano and Giovanni D’Addio},
   doi = {10.1038/s41598-020-77243-3},
   isbn = {0123456789},
   issn = {2045-2322},
   issue = {1},
   journal = {Scientific Reports 2020 10:1},
   keywords = {Engineering,Neurology},
   month = {11},
   pages = {1-10},
   pmid = {33208913},
   publisher = {Nature Publishing Group},
   title = {Machine learning to predict mortality after rehabilitation among patients with severe stroke},
   volume = {10},
   url = {https://www.nature.com/articles/s41598-020-77243-3},
   year = {2020},
}
@article{Yu2020,
   abstract = {Recently, with the rapid change to an aging society and the increased interest in healthcare, disease prediction and management through various healthcare devices and services is attracting much attention. In particular, stroke, represented by cerebrovascular disease, is a very dangerous disease, in which death or mental and physical aftereffects are very large in adults and the elderly. The sequelae of such stroke diseases are very dangerous, because they make social and economic activities difficult. In this paper, we propose a new system to prediction and in-depth analysis stroke severity of elderly over 65 years based on the National Institutes of Health Stroke Scale (NIHSS). In addition, we use the algorithm of decision tree of C4.5, which is a methodology of prediction and analysis of machine learning techniques. The C4.5 decision trees are machine learning algorithms that provide additional in-depth rules of the execution mechanism and semantic interpretation analysis. Finally, in this paper, it is verified that the C4.5 decision tree algorithm can be used to classify and predict stroke severity, and to obtain additional NIHSS features reduction effects. Therefore, during the operation of an actual system, the proposed model uses only 13 features out of the 18 stroke scale features, including age, so that it can provide faster and more accurate service support. Experimental results show that the system enables this by reducing the patient NIH stroke scale measurement time and making the operation more efficient, with an overall accuracy, using the C4.5 decision tree algorithm, of 91.11%.},
   author = {Jaehak Yu and Sejin Park and Hansung Lee and Cheol Sig Pyo and Yang Sun Lee},
   doi = {10.3390/MATH8071115},
   issn = {2227-7390},
   issue = {7},
   journal = {Mathematics 2020, Vol. 8, Page 1115},
   keywords = {National Institutes of Health Stroke Scale (NIHSS),health monitoring system,machine learning,stroke analysis,stroke severity prediction},
   month = {7},
   pages = {1115},
   publisher = {Multidisciplinary Digital Publishing Institute},
   title = {An Elderly Health Monitoring System Using Machine Learning and In-Depth Analysis Techniques on the NIH Stroke Scale},
   volume = {8},
   url = {https://www.mdpi.com/2227-7390/8/7/1115/htm https://www.mdpi.com/2227-7390/8/7/1115},
   year = {2020},
}
@article{Xie2018,
   abstract = {OBJECTIVE. When treatment decisions are being made for patients with acute ischemic stroke, timely and accurate outcome prediction plays an important role. The optimal rehabilitation strategy also ...},
   author = {Yuan Xie and Bin Jiang and Enhao Gong and Ying Li and Guangming Zhu and Patrik Michel and Max Wintermark and Greg Zaharchuk},
   doi = {10.2214/AJR.18.20260},
   issn = {15463141},
   issue = {1},
   journal = {https://doi.org/10.2214/AJR.18.20260},
   keywords = {CT,machine learning,modified Rankin scale,prediction,stroke},
   month = {10},
   pages = {44-51},
   pmid = {30354266},
   publisher = { American Roentgen Ray Society },
   title = {Use of Gradient Boosting Machine Learning to Predict Patient Outcome in Acute Ischemic Stroke on the Basis of Imaging, Demographic, and Clinical Information},
   volume = {212},
   url = {www.ajronline.org},
   year = {2018},
}

@article{Rojas2012,
   abstract = {INTRODUCCIÓN La diabetes mellitus es una enfermedad crónica, considerada un problema de salud pública, Venezuela no escapa a esta situación en la que cada año aumenta el número de personas afectadas. Dada la magnitud de la población en riesgo de padecer la enfermedad, resulta imposible que todos los pacientes sean atendidos por el médico especialista, por lo tanto es necesario que los de atención primaria cuenten con herramientas, sencillas y actualizadas que les permitan el abordaje, la evaluación y el tratamiento del paciente diabético, así como decidir cuándo deberían referirlo al especialista (endocrinólogo, oftalmólogo, nefrólogo etc.). DEFINICIÓN La diabetes mellitus es un grupo de alteraciones metabólicas que se caracteriza por hiperglucemia crónica, debida a un defecto en la secreción de la insulina, a un defecto en la acción de la misma, o a ambas. Además de la hiperglucemia, coexisten alteraciones en el metabolismo de las grasas y de las proteínas. La hiperglucemia sostenida en el tiempo se asocia con daño, disfunción y falla de varios órganos y sistemas, especialmente riñones, ojos, nervios, corazón y vasos sanguíneos 1-5 .},
   author = {Dra Elizabeth Rojas and Dra Rusty Molina and Cruz Rodríguez},
   issn = {1690-3110},
   journal = {Revista Venezolana de Endocrinología y Metabolismo},
   pages = {7-12},
   publisher = {Sociedad Venezolana de Endocrinología y Metabolismo},
   title = {Definición, clasificación y diagnóstico de la diabetes mellitus},
   volume = {10},
   url = {http://ve.scielo.org/scielo.php?script=sci_arttext\&pid=S1690-31102012000400003\&lng=es\&nrm=iso\&tlng=es http://ve.scielo.org/scielo.php?script=sci_abstract\&pid=S1690-31102012000400003\&lng=es\&nrm=iso\&tlng=es},
   year = {2012},
}
@article{Bar2017,
   abstract = {One of the most common problems facing empirical researchers is when a portion of the data is missing. We will review three different types of ‘missingness’, namely missing completely at random, mi...},
   author = {Haim Bar},
   doi = {10.1080/11356405.2017.1365426},
   issn = {15784118},
   issue = {3},
   journal = {https://doi.org/10.1080/11356405.2017.1365426},
   keywords = {chained equations,datos ausentes,ecuaciones encadenadas,imputación múltiple,missing data,multiple imputation},
   pages = {492-525},
   publisher = {Routledge},
   title = {Missing data — mechanisms and possible solutions / Datos ausentes: mecanismos y posibles soluciones},
   volume = {29},
   url = {https://www.tandfonline.com/doi/abs/10.1080/11356405.2017.1365426},
   year = {2017},
}
@article{Morales-Plaza,
   abstract = {Objective: Identify predictors of stroke mortality (ACV) at the Hospital Universitario San Jorge de Pereira, between January 2008 and December 2011. Materials and methods: Cross sectional study, realized in patients with a diagnosis of stroke. Information was obtained from medical records taking into account patient age, sex, type of stroke (ischemic or hemorrhagic), associated disorder, personal history associated with stroke mortality. We applied logistic regression models to determine which variables were significantly associated with mortality. Results: 350 patients evaluated. Mean age 69.2 years + / -11.6 years, 51.4 \% of the participants were women; 57.4 \% had a sudden episode, 78.6 \% of ischemic ACV and 21.4 \% was bleeding. Disorders in order of appearance were: Motor deficit (80.9 \%), language deficits (43.4 \%), headache (35.7 \%), and cranial nerve disorder (28.3 \%). Comorbidities were hypertension (72.6 \%), dyslipidemia (47.7 \%), diabetes mellitus (19.7 \%), smoking (17.4 \%), ischemic heart disease (9.4\%), previous ACV (6 \%) and atrial fibrillation (6 \%); 16 \% of patients died from stroke, of these, 74.6 \% were bleeding. Statistically significant association was found between mortality from stroke and sudden onset (OR 0.65; IC 95\%:0.021-0.200, p <0.001), intraparenchymal hemorrhage (OR: 91.3; IC95 \%:20.6- 403.7; p<0.001) and age between 40 and 55 years (OR: 2.91; IC95 \%:2.07-5.18; p<0.001). Discussion: Since the variables associated with death are not modifiable at patient’s admission to hospital, should reinforce the public health measures to prevent the occurrence of stroke.},
   author = {Cristhian David Morales-Plaza and Claudio Aguirre-Castañeda and Jorge Enrique Machado-Alba},
   doi = {10.14482/SUN.32.1.8520},
   issn = {0120-5552},
   issue = {1},
   journal = {Revista Salud Uninorte},
   keywords = {Cerebral hemorrhage,Comorbidity,Middle aged,Mortality,Risks factors,Stroke},
   month = {1},
   pages = {56-64},
   publisher = {Fundación Universidad del Norte},
   title = {Factores predictores de mortalidad por accidente cerebrovascular en el Hospital Universitario San Jorge de Pereira (Colombia)},
   volume = {32},
   url = {http://www.scielo.org.co/scielo.php?script=sci\_arttext\&pid=S0120-55522016000100005\&lng=en\&nrm=iso\&tlng=es http://www.scielo.org.co/scielo.php?script=sci_abstract\&pid=S0120-55522016000100005\&lng=en\&nrm=iso\&tlng=es},
   year = {2016},
}
@article{Gabbe2003,
   abstract = {The Glasgow Coma Scale (GCS) was first introduced in the 1970s to provide a simple and reliable method of recording and monitoring change in the level of consciousness of head injured patients. Since its introduction, the GCS has been widely utilized in the trauma community and its use expanded beyond the original intentions of the score. In the context of traumatic injury, this paper discusses the use of the GCS as a predictor of outcome, the limitations of the GCS, the reliability of the GCS and potential alternatives through a critical review of the literature. The relevance to Australian trauma populations is also addressed.},
   author = {Belinda J. Gabbe and Peter A. Cameron and Caroline F. Finch},
   doi = {10.1046/J.1442-2026.2003.00474.X},
   issn = {1035-6851},
   issue = {4},
   journal = {Emergency medicine (Fremantle, W.A.)},
   keywords = {Belinda J Gabbe,Caroline F Finch,Emergency Service,Glasgow Coma Scale* / statistics & numerical data,Health Care,Hospital,Humans,MEDLINE,NCBI,NIH,NLM,National Center for Biotechnology Information,National Institutes of Health,National Library of Medicine,Non-U.S. Gov't,Observer Variation,Outcome and Process Assessment,Peter A Cameron,PubMed Abstract,Reproducibility of Results,Research Support,Review,Sensitivity and Specificity,Wounds and Injuries,doi:10.1046/j.1442-2026.2003.00474.x,pmid:14631703},
   month = {8},
   pages = {353-360},
   pmid = {14631703},
   publisher = {Emerg Med (Fremantle)},
   title = {The status of the Glasgow Coma Scale},
   volume = {15},
   url = {https://pubmed.ncbi.nlm.nih.gov/14631703/},
   year = {2003},
}
@article{cien2001,
   author = {F\'elix. Bermejo Pareja and Jaime. Di\'iaz Guzm\'an and Jes\'us. Porta-Etessam},
   isbn = {84-8124-184-9},
   keywords = {616.8-072.8,Cien escalas de inter\'es en neurología cl\'inica,Escalas de evaluaci\'on psiqui\'atrica,Libro},
   publisher = {Prous Science},
   title = {Cien escalas de interés en neurolog\'ia cl\'inica},
   url = {https://dialnet.unirioja.es/servlet/libro?codigo=244189},
   year = {2001},
}
@article{Hancock2020,
   abstract = {This survey investigates current techniques for representing qualitative data for use as input to neural networks. Techniques for using qualitative data in neural networks are well known. However, researchers continue to discover new variations or entirely new methods for working with categorical data in neural networks. Our primary contribution is to cover these representation techniques in a single work. Practitioners working with big data often have a need to encode categorical values in their datasets in order to leverage machine learning algorithms. Moreover, the size of data sets we consider as big data may cause one to reject some encoding techniques as impractical, due to their running time complexity. Neural networks take vectors of real numbers as inputs. One must use a technique to map qualitative values to numerical values before using them as input to a neural network. These techniques are known as embeddings, encodings, representations, or distributed representations. Another contribution this work makes is to provide references for the source code of various techniques, where we are able to verify the authenticity of the source code. We cover recent research in several domains where researchers use categorical data in neural networks. Some of these domains are natural language processing, fraud detection, and clinical document automation. This study provides a starting point for research in determining which techniques for preparing qualitative data for use with neural networks are best. It is our intention that the reader should use these implementations as a starting point to design experiments to evaluate various techniques for working with qualitative data in neural networks. The third contribution we make in this work is a new perspective on techniques for using categorical data in neural networks. We organize techniques for using categorical data in neural networks into three categories. We find three distinct patterns in techniques that identify a technique as determined, algorithmic, or automated. The fourth contribution we make is to identify several opportunities for future research. The form of the data that one uses as an input to a neural network is crucial for using neural networks effectively. This work is a tool for researchers to find the most effective technique for working with categorical data in neural networks, in big data settings. To the best of our knowledge this is the first in-depth look at techniques for working with categorical data in neural networks.},
   author = {John T. Hancock and Taghi M. Khoshgoftaar},
   doi = {10.1186/S40537-020-00305-W/FIGURES/4},
   issn = {21961115},
   issue = {1},
   journal = {Journal of Big Data},
   keywords = {Big data,Deep learning,Embedding,Encoding,Neural networks,Qualitative data},
   month = {12},
   pages = {1-41},
   publisher = {Springer},
   title = {Survey on categorical data for neural networks},
   volume = {7},
   url = {https://journalofbigdata.springeropen.com/articles/10.1186/s40537-020-00305-w},
   year = {2020},
}
@article{Ge2003,
   abstract = {This article describes some internals of the design and implementation of an interpreted programming environment for scientific computing. A high level, hybrid approach to numerical computations is discussed with examples focused on sparse matrix computations. © Springer-Verlag Berlin Heidelberg 2003.},
   author = {Baolai Ge},
   doi = {10.1007/3-540-44839-X_70/COVER},
   isbn = {3540401555},
   issn = {16113349},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   keywords = {High level programming environment,Iterative methods,Least squares approximate inverses,Linear systems,Preconditioning},
   pages = {663-673},
   publisher = {Springer Verlag},
   title = {Programming in a high level approach for scientific computing},
   volume = {2667},
   url = {https://link.springer.com/chapter/10.1007/3-540-44839-X_70},
   year = {2003},
}
@article{Mosquera2018,
   abstract = {This paper presents a new methodology based on the application of Support Vector Machine algorithms, Naïve Bayes and Genetic Algorithms in diagnostics of psychosocial evaluations for the identification and prediction of the psychosocial risk level of public-school teachers in Colombia. A comparative study of the model of machine learning for prediction was carried out: Support Vector Machines (SVM) and Naïve Bayes, in two stages, first with all the variables and second, reducing the dimensionality of the database applying genetic algorithms, The best forty variables with the best efficiency in prediction accuracy were selected. The database used consisted of 3000 epidemiological records, which corresponded to teachers from public schools in the metropolitan area of a Colombian city. The use of SVM easily detected variables of physiological type and the best prediction performance was obtained with accuracy of 96.3%.},
   author = {Rodolfo Mosquera and Omar D. Castrillón and Liliana Parra and Rodolfo Mosquera and Omar D. Castrillón and Liliana Parra},
   doi = {10.4067/S0718-07642018000600153},
   issn = {0718-0764},
   issue = {6},
   journal = {Información tecnológica},
   keywords = {Genetic algorithm,Machine learning,Naïve Bayes,Support vector machine},
   month = {12},
   pages = {153-162},
   publisher = {Centro de Información Tecnológica},
   title = {Máquinas de Soporte Vectorial, Clasificador Naïve Bayes y Algoritmos Genéticos para la Predicción de Riesgos Psicosociales en Docentes de Colegios Públicos Colombianos},
   volume = {29},
   url = {http://www.scielo.cl/scielo.php?script=sci\_arttext\&pid=S0718-07642018000600153\&lng=es\&nrm=iso\&tlng=es http://www.scielo.cl/scielo.php?script=sci_abstract\&pid=S0718-07642018000600153\&lng=es\&nrm=iso\&tlng=es},
   year = {2018},
}
@article{ Sulla-Torres,
   abstract = {The decision tree technique in the health sciences serves to understand the correlations between the descriptions of patients and to classify accurately in various categories. The aim of the study was to analyze the accuracy of the classification of excess weight of schoolchildren through the application of a fuzzy decision tree, using a database of Itaupú, Paraná (Brazil). We used the database of a sample consisting of 5962 students (3024 female and 2938 male), with an age range between 6 to 17 years of age. The variables considered were weight, height and the Body Mass Index (BMI). To classify the anthropometric data of the students, a diffuse decision tree was used. The learning results showed a correct classification in the female sex of 2688 and in the male sex of 2471 records respectively. In relation to accuracy, 84\% was determined in the male sex and 89\% in the female sex. The Area under the curve showed higher values in the Fuzzy method and in both sexes (0.965-0.983), while in the classical method, they were lower (0.804-0.895). According to the calculated results it is possible to apply the fuzzy decision tree for the classification of overweight students with an acceptable accuracy, and it is presented as an alternative technique that can save time when analyzing the nutritional status, however, no other statistical calculations were made that have to do with the precision and accuracy through conventional statistical methods and compare with the technique of fuzzy trees.},
   author = {J. Sulla-Torres and R. Gómez-Campos and M.A. Cossio-Bolaños and J. Sulla-Torres and R. Gómez-Campos and M.A. Cossio-Bolaños},
   doi = {10.17488/RMIB.39.2.1},
   issn = {0188-9532},
   issue = {2},
   journal = {Revista mexicana de ingeniería biomédica},
   keywords = {Ambiguity,Classification obesity,Fuzzy decision trees,Vagueness},
   pages = {128-143},
   publisher = {Sociedad Mexicana de Ingeniería Biomédica},
   title = {Aplicación de un árbol de decisión difusa con clasificación de ambigüedad para determinar el exceso de peso en escolares},
   volume = {39},
   url = {http://www.scielo.org.mx/scielo.php?script=sci_arttext\&pid=S0188-95322018000200128\&lng=es\&nrm=iso\&tlng=es http://www.scielo.org.mx/scielo.php?script=sci_abstract\&pid=S0188-95322018000200128\&lng=es\&nrm=iso\&tlng=es},
   year = {2018},
}
@web_page{ProjectManagement ,
   title = {Project Management in Data Science using OSEMN | by Mukesh Kumar | INSAID | Medium},
   url = {https://medium.com/international-school-of-ai-data-science/project-management-in-data-science-using-osemn-50e46f95eec7},
}
@article{Adams1999,
   abstract = {Objective: To compare the baseline National Institutes of Health Stroke Scale (NIHSS) score and the Trial of Org 10172 in Acute Stroke Treatment (TOAST) stroke subtype as predictors of outcomes at 7 days and 3 months after ischemic stroke. Methods: Using data collected from 1,281 patients enrolled in a clinical trial, subtype of stroke was categorized using the TOAST classification, and neurologic impairment at baseline was quantified using the NIHSS. Outcomes were assessed at 7 days and 3 months using the Barthel Index (BI) and the Glasgow Outcome Scale (GOS). An outcome was rated as excellent if the GOS score was I and the BI was 19 or 20 (scale of 0 to 20). Analyses were adjusted for age, sex, race, and history of previous stroke. Results: The baseline NIHSS score strongly predicted outcome, with one additional point on the NIHSS decreasing the likelihood of excellent outcomes at 7 days by 24\% and at 3 months by 17\%. At 3 months, excellent outcomes were noted in 46\% of patients with NIHSS scores of 7 to 10 and in 23\% of patients with scores of 11 to 15. After multivariate adjustment, lacunar stroke had an odds ratio of 3.1 (95\% CI, 1.5 to 6 4) for an excellent outcome at 3 months. Conclusions: The NIHSS score strongly predicts the likelihood of a patient's recovery after stroke. A score of ≥16 forecasts a high probability of death or severe disability whereas a score of ≤6 forecasts a good recovery. Only the TOAST subtype of lacunar stroke predicts outcomes independent of the NIHSS score.},
   author = {Harold P. Adams and P. H. Davis and E. C. Leira and K. C. Chang and B. H. Bendixen and W. R. Clarke and R. F. Woolson and M. D. Hansen},
   doi = {10.1212/WNL.53.1.126},
   issn = {0028-3878},
   issue = {1},
   journal = {Neurology},
   keywords = {Anticoagulants / therapeutic use*,Cerebrovascular Disorders / classification*,Cerebrovascular Disorders / drug therapy*,Cerebrovascular Disorders / physiopathology,Chondroitin Sulfates / therapeutic use*,Clinical Trial,Comparative Study,Dermatan Sulfate / therapeutic use*,Female,Follow-Up Studies,Glasgow Coma Scale,H P Adams,Heparitin Sulfate / therapeutic use*,Humans,M D Hansen,MEDLINE,Male,Multicenter Study,NCBI,NIH,NLM,National Center for Biotechnology Information,National Institutes of Health,National Institutes of Health (U.S.),National Library of Medicine,P H Davis,P.H.S.,Probability,PubMed Abstract,Randomized Controlled Trial,Research Support,Time Factors,Trauma Severity Indices*,Treatment Outcome,U.S. Gov't,United States,doi:10.1212/wnl.53.1.126,pmid:10408548},
   month = {7},
   pages = {126-131},
   pmid = {10408548},
   publisher = {Neurology},
   title = {Baseline NIH Stroke Scale score strongly predicts outcome after stroke: A report of the Trial of Org 10172 in Acute Stroke Treatment (TOAST)},
   volume = {53},
   url = {https://pubmed.ncbi.nlm.nih.gov/10408548/},
   year = {1999},
}
@article{Meyer2009,
   abstract = {The National Institutes of Health Stroke Scale (NIHSS) is a well known, reliable and valid stroke deficit scale. The NIHSS is simple, quick, and has shown significant reliability in diverse groups, settings, and languages. The NIHSS also contains items with poor reliability and redundancy. Recent investigations (include assessing a new training DVD, analyzing webbased or videotape certifications, and testing foreign language versions) have further detailed reliability issues. Items recurrently shown to have poor reliability include Level of Consciousness, Facial Palsy, Limb Ataxia, and Dysarthria. The modified NIHSS (mNIHSS) minimizes redundancy and eliminates poorly reliable items. The mNIHSS shows greater reliability in multiple settings and cohorts, including scores abstracted from records, when used via telemedicine, and when used in clinical trials. In a validation of the mNIHSS against the NIHSS, the number of elements with excellent agreement increased from 54\% to 71\%, while poor agreement decreased from 12\% to 5\%. Overall, 45\% of NIHSS items had less than excellent reliability vs. only 29\% for the mNIHSS. The mNIHSS is not the ideal stroke scale, but it is a significant improvement over the NIHSS. The mNIHSS has shown reliability at bedside, with record abstraction, with telemedicine, and in clinical trials. Since the mNIHSS is more reliable, it may allow for improved practitioner communication, improved medical care, and refinement of trial enrollments. The mNIHSS should now serve as the primary stroke clinical deficit scale for clinical and research aims. When it comes to the mNIHSS, its time has come! © 2009 World Stroke Organization.},
   author = {Brett C. Meyer and P. D. Lyden},
   doi = {10.1111/J.1747-4949.2009.00294.X},
   issn = {17474930},
   issue = {4},
   journal = {International journal of stroke : official journal of the International Stroke Society},
   keywords = {Modified,NIHSS,Reliability,Stroke scale,mNIHSS},
   pages = {267},
   pmid = {19689755},
   publisher = {NIH Public Access},
   title = {The Modified National Institutes of Health Stroke Scale (mNIHSS): Its Time Has Come},
   volume = {4},
   url = {/pmc/articles/PMC2729912/ /pmc/articles/PMC2729912/?report=abstract https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2729912/},
   year = {2009},
}
@article{Bank1993,
   abstract = {Routines callable from Fortran and C are described which implement matrix-matrix multiplication and transposition for a variety of sparse matrix formats. Conversion routines between various formats are provided. © 1993 J.C. Baltzer AG, Science Publishers.},
   author = {Randolph E. Bank and Craig C. Douglas},
   doi = {10.1007/BF02070824/METRICS},
   issn = {10197168},
   issue = {1},
   journal = {Advances in Computational Mathematics},
   keywords = {Sparse matrices,Subject classification AMS(MOS): Numerical analysis, numerical linear algebra,matrix multiplication,numerical linear algebra,transposition},
   month = {2},
   pages = {127-137},
   publisher = {Baltzer Science Publishers, Baarn/Kluwer Academic Publishers},
   title = {Sparse matrix multiplication package (SMMP)},
   volume = {1},
   url = {https://link.springer.com/article/10.1007/BF02070824},
   year = {1993},
}
@web_page{med,
   title = {Conteo de glóbulos blancos - Serie—Resultados: MedlinePlus enciclopedia médica},
   url = {https://medlineplus.gov/spanish/ency/esp_presentations/100151\_3.htm},
}
@article{Cid-Ruzafa,
   author = {Javier Cid-Ruzafa and Javier Damián-Moreno},
   journal = {Revista española de salud pública},
   pages = {127-137},
   publisher = {SciELO Public Health},
   title = {Valoración de la discapacidad f\'\isica: el \'\indice de Barthel},
   volume = {71},
   year = {1997},
}
@article{Zarco2008,
   author = {Luis Alfonso Zarco and Freddy González and JULIANA CORAL CASAS},
   issue = {4},
   journal = {Universitas Médica},
   pages = {467-498},
   publisher = {Pontificia Universidad Javeriana},
   title = {Tratamiento actual del ataque cerebrovascular isquémico (ACV) agudo},
   volume = {49},
   year = {2008},
}
@book{Harrington2012,
   author = {Peter Harrington},
   edition = {Manning Publications},
   editor = {Peter Harrington},
   isbn = {9781617290183},
   title = {Machine Learning in Action},
   url = {https://books.google.cl/books?hl=es\&lr=\&id=XTozEAAAQBAJ\&oi=fnd\&pg=PT18\&dq=Harrington,+P.,+2012\&ots=pw1kM8GKdp\&sig=7qI5Th2iA\_GYNsS\_lW0dyeMHKlA},
   year = {2012},
}
@phdthesis{moreno2021diseno,
  title={Dise{\~n}o de una aplicaci{\'o}n de data science para la predicci{\'o}n del rendimiento acad{\'e}mico de los estudiantes de la Unidad Educativa “Jos{\'e} El{\'\i}as Altamirano”, a{\~n}o 2021},
  author={Moreno Herrera, Mirna Alexandra and Reyes Maldonado, Melanie Gabriela},
  year={2021},
  school={Universidad de Guayaquil. Facultad de Ciencias Matem{\'a}ticas y F{\'\i}sicas~…}
}
@article{murdoch2019interpretable,
  title={Interpretable machine learning: definitions, methods, and applications},
  author={Murdoch, W James and Singh, Chandan and Kumbier, Karl and Abbasi-Asl, Reza and Yu, Bin},
  journal={arXiv preprint arXiv:1901.04592},
  year={2019}
}
@article{salas2004redes,
  title={Redes neuronales artificiales},
  author={Salas, Rodrigo},
  journal={Universidad de Valpara{\i}so. Departamento de Computaci{\'o}n},
  volume={1},
  pages={1--7},
  year={2004}
}
@techreport{arana2021redes,
  title={Redes neuronales recurrentes: An{\'a}lisis de los modelos especializados en datos secuenciales},
  author={Arana, Carlos},
  year={2021},
  institution={Serie Documentos de Trabajo}
}
@inproceedings{NIPS2012_c399862d,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 url = {https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
 volume = {25},
 year = {2012}
}
@article{shao2018improved,
  title={An Improved Deep Learning Model for Traffic Crash Prediction},
  author={Shao, Chunfu Shao and Xiong, Zhihua Xiong and Dong, Chunjiao Dong and Dong, Chunjiao and Li, Juan Li},
  year={2018}
}

@web_page{Kumar2022,
   author = {Mukesh Kumar},
   title = {Project Management in Data Science using OSEMN | by Mukesh Kumar | INSAID | Medium},
   url = {https://medium.com/international-school-of-ai-data-science/project-management-in-data-science-using-osemn-50e46f95eec7},
   year = {2022},
}
